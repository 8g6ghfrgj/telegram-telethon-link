import sqlite3
import logging
import os
import json
import csv
import shutil
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple, Any, Union
from enum import Enum
import threading

from config import DATABASE_PATH, DATA_DIR, EXPORT_DIR, EXPORT_ENCODING, BACKUP_DIR

# ======================
# Configuration
# ======================

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø­Ù…Ø§ÙŠØ©
FORCE_DELETE = False  # ÙŠØ¬Ø¨ ØªØ¹ÙŠÙŠÙ†Ù‡Ø§ ÙŠØ¯ÙˆÙŠØ§Ù‹ Ù„Ù„Ø³Ù…Ø§Ø­ Ø¨Ø§Ù„Ø­Ø°Ù Ø§Ù„ÙƒØ§Ù…Ù„
PROTECTED_TABLES = ['links', 'sessions']  # Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø­Ù…ÙŠØ©
MAX_BACKUPS = 10  # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø¹Ø¯Ø¯ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©

# ======================
# Logging
# ======================

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ======================
# Constants & Enums
# ======================

class LinkType(Enum):
    """ØªØ­Ø¯ÙŠØ¯ Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¨Ø´ÙƒÙ„ Ø«Ø§Ø¨Øª ÙˆÙ…ØªØ³Ù‚"""
    # Telegram - Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø© ÙÙ‚Ø·
    TELEGRAM_PUBLIC_GROUP = "public_group"
    TELEGRAM_PRIVATE_GROUP = "private_group"
    TELEGRAM_JOIN_REQUEST = "join_request"
    
    # WhatsApp
    WHATSAPP_GROUP = "group"
    
    @classmethod
    def get_all_types(cls):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù†Ø´Ø·Ø©"""
        return [
            cls.TELEGRAM_PUBLIC_GROUP.value,
            cls.TELEGRAM_PRIVATE_GROUP.value,
            cls.TELEGRAM_JOIN_REQUEST.value,
            cls.WHATSAPP_GROUP.value,
        ]
    
    @classmethod
    def get_telegram_types(cls):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø§Ù„Ù†Ø´Ø·Ø©"""
        return [
            cls.TELEGRAM_PUBLIC_GROUP.value,
            cls.TELEGRAM_PRIVATE_GROUP.value,
            cls.TELEGRAM_JOIN_REQUEST.value,
        ]
    
    @classmethod
    def get_whatsapp_types(cls):
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø£Ù†ÙˆØ§Ø¹ ÙˆØ§ØªØ³Ø§Ø¨ Ø§Ù„Ù†Ø´Ø·Ø©"""
        return [cls.WHATSAPP_GROUP.value]
    
    @classmethod
    def is_valid_type(cls, platform: str, link_type: str) -> bool:
        """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ù†ÙˆØ¹ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„Ù…Ù†ØµØ©"""
        if platform == "telegram":
            return link_type in cls.get_telegram_types()
        elif platform == "whatsapp":
            return link_type in cls.get_whatsapp_types()
        return False

# ======================
# Database Connection with Transactions
# ======================

class DatabaseConnection:
    """Ù…Ø¯ÙŠØ± Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø­Ù…Ø§ÙŠØ© Ù…ØªÙ‚Ø¯Ù…Ø©"""
    
    @staticmethod
    def get_connection():
        """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø¬Ù„Ø¯ data
            os.makedirs(os.path.dirname(DATABASE_PATH), exist_ok=True)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„
            conn = sqlite3.connect(DATABASE_PATH, check_same_thread=False)
            conn.row_factory = sqlite3.Row
            
            # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
            conn.execute('PRAGMA journal_mode = WAL')
            conn.execute('PRAGMA synchronous = NORMAL')
            conn.execute('PRAGMA cache_size = -2000')
            conn.execute('PRAGMA foreign_keys = ON')
            
            return conn
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§ØªØµØ§Ù„ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† Ø§Ù„Ø­Ø°Ù
            if DatabaseConnection.repair_database():
                return DatabaseConnection.get_connection()
            else:
                logger.critical("âŒ ÙØ´Ù„ Ø¥ØµÙ„Ø§Ø­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§ØªØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ­Ù‚Ù‚ ÙŠØ¯ÙˆÙŠØ§Ù‹")
                raise
    
    @staticmethod
    def backup_database():
        """Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ù…Ù† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
        try:
            os.makedirs(BACKUP_DIR, exist_ok=True)
            
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
            DatabaseConnection.cleanup_old_backups()
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = os.path.join(BACKUP_DIR, f"backup_{timestamp}.db")
            
            if os.path.exists(DATABASE_PATH):
                shutil.copy2(DATABASE_PATH, backup_path)
                logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_path}")
                return backup_path
            
            logger.warning("âš ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ")
            return None
            
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
            return None
    
    @staticmethod
    def cleanup_old_backups():
        """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©"""
        try:
            if not os.path.exists(BACKUP_DIR):
                return
            
            backups = []
            for filename in os.listdir(BACKUP_DIR):
                if filename.startswith("backup_") and filename.endswith(".db"):
                    filepath = os.path.join(BACKUP_DIR, filename)
                    mtime = os.path.getmtime(filepath)
                    backups.append((mtime, filepath))
            
            # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„ØªØ§Ø±ÙŠØ® (Ø§Ù„Ø£Ù‚Ø¯Ù… Ø£ÙˆÙ„Ø§Ù‹)
            backups.sort()
            
            # Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø²Ø§Ø¦Ø¯Ø© Ø¹Ù† Ø§Ù„Ø­Ø¯
            if len(backups) > MAX_BACKUPS:
                for i in range(len(backups) - MAX_BACKUPS):
                    os.remove(backups[i][1])
                    logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {backups[i][1]}")
                    
        except Exception as e:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {e}")
    
    @staticmethod
    def repair_database():
        """Ø¥ØµÙ„Ø§Ø­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ù„ÙØ©"""
        try:
            if not os.path.exists(DATABASE_PATH):
                logger.info("â„¹ï¸ Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ù…Ù„Ù Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø¥ØµÙ„Ø§Ø­")
                return True
            
            # 1. Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ© Ø£ÙˆÙ„Ø§Ù‹
            backup = DatabaseConnection.backup_database()
            if not backup:
                logger.error("âŒ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø§Ù„Ø¥ØµÙ„Ø§Ø­ Ø¨Ø¯ÙˆÙ† Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©")
                return False
            
            # 2. Ù…Ø­Ø§ÙˆÙ„Ø© ÙØªØ­ ÙˆØ¥ØµÙ„Ø§Ø­
            conn = None
            try:
                conn = sqlite3.connect(DATABASE_PATH)
                cursor = conn.cursor()
                
                # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
                cursor.execute("PRAGMA integrity_check")
                result = cursor.fetchone()[0]
                
                if result == "ok":
                    logger.info("âœ… ÙØ­Øµ Ø³Ù„Ø§Ù…Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù†Ø§Ø¬Ø­")
                    conn.close()
                    return True
                else:
                    logger.warning(f"âš ï¸ Ù…Ø´ÙƒÙ„Ø© ÙÙŠ Ø³Ù„Ø§Ù…Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {result}")
                    
                    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­
                    cursor.execute("PRAGMA optimize")
                    cursor.execute("VACUUM")
                    conn.commit()
                    
                    cursor.execute("PRAGMA integrity_check")
                    result = cursor.fetchone()[0]
                    
                    if result == "ok":
                        logger.info("âœ… ØªÙ… Ø¥ØµÙ„Ø§Ø­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
                        return True
                    else:
                        logger.error(f"âŒ ÙØ´Ù„ Ø¥ØµÙ„Ø§Ø­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {result}")
                        return False
                        
            except Exception as e:
                logger.error(f"âŒ Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø¥ØµÙ„Ø§Ø­: {e}")
                return False
            finally:
                if conn:
                    conn.close()
                    
        except Exception as e:
            logger.error(f"âŒ Ø®Ø·Ø£ Ø¹Ø§Ù… ÙÙŠ Ø§Ù„Ø¥ØµÙ„Ø§Ø­: {e}")
            return False

# ======================
# Transaction Decorator
# ======================

def transaction(func):
    """Ø¯ÙŠÙƒÙˆØ±Ø§ØªÙˆØ± Ù„Ø¥Ø¯Ø§Ø±Ø© Transactions"""
    def wrapper(*args, **kwargs):
        conn = None
        cursor = None
        try:
            conn = DatabaseConnection.get_connection()
            cursor = conn.cursor()
            
            # Ø¨Ø¯Ø¡ Transaction
            cursor.execute("BEGIN TRANSACTION")
            
            # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¯Ø§Ù„Ø©
            result = func(*args, **kwargs, conn=conn, cursor=cursor)
            
            # ØªØ£ÙƒÙŠØ¯ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
            conn.commit()
            return result
            
        except Exception as e:
            # Ø§Ù„ØªØ±Ø§Ø¬Ø¹ Ø¹Ù† Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
            if conn:
                conn.rollback()
            logger.error(f"âŒ ÙØ´Ù„Øª Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø© ÙÙŠ {func.__name__}: {e}")
            raise
            
        finally:
            # Ø¥ØºÙ„Ø§Ù‚ Ø§Ù„Ø§ØªØµØ§Ù„
            if cursor:
                cursor.close()
            if conn:
                conn.close()
                
    return wrapper

# ======================
# Database Initialization
# ======================

def init_db():
    """ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„"""
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ØµÙ„Ø§Ø­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ù„ÙØ©
        if os.path.exists(DATABASE_PATH):
            if not DatabaseConnection.repair_database():
                logger.error("âŒ ÙØ´Ù„ Ø¥ØµÙ„Ø§Ø­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©")
                return False
        
        conn = DatabaseConnection.get_connection()
        cursor = conn.cursor()
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¬Ù„Ø³Ø§Øª
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_string TEXT NOT NULL UNIQUE,
                phone_number TEXT,
                user_id INTEGER,
                username TEXT,
                display_name TEXT,
                is_active BOOLEAN DEFAULT 1,
                added_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                last_used TIMESTAMP,
                notes TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· - Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù†Ø´Ø·Ø© ÙÙ‚Ø·
        cursor.execute(f'''
            CREATE TABLE IF NOT EXISTS links (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                url TEXT NOT NULL UNIQUE,
                platform TEXT NOT NULL,
                link_type TEXT NOT NULL,
                title TEXT,
                description TEXT,
                members_count INTEGER DEFAULT 0,
                is_active BOOLEAN DEFAULT 1,
                collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                collected_by INTEGER,
                session_id INTEGER,
                metadata TEXT,
                last_checked TIMESTAMP,
                checked_count INTEGER DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (session_id) REFERENCES sessions (id) ON DELETE SET NULL,
                CHECK (platform IN ('telegram', 'whatsapp')),
                CHECK (link_type IN ({','.join(['?'] * len(LinkType.get_all_types()))}))
            )
        ''', LinkType.get_all_types())
        
        # Ø¬Ø¯ÙˆÙ„ Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ø¬Ù…Ø¹
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS collection_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                start_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                end_time TIMESTAMP,
                status TEXT DEFAULT 'stopped',
                stats TEXT,
                total_links INTEGER DEFAULT 0,
                duplicate_links INTEGER DEFAULT 0,
                inactive_links INTEGER DEFAULT 0,
                channels_skipped INTEGER DEFAULT 0,
                platform TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ Ø³Ø¬Ù„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS change_log (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                table_name TEXT NOT NULL,
                record_id INTEGER NOT NULL,
                action TEXT NOT NULL,
                old_data TEXT,
                new_data TEXT,
                changed_by TEXT,
                changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        
        # ÙÙ‡Ø§Ø±Ø³ Ù„Ù„ØªØ­Ø³ÙŠÙ†
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_links_platform_type 
            ON links(platform, link_type, is_active)
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_links_collected_at 
            ON links(collected_at DESC)
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_links_is_active 
            ON links(is_active)
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_links_url 
            ON links(url)
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_sessions_active 
            ON sessions(is_active)
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_links_last_checked 
            ON links(last_checked)
        ''')
        
        conn.commit()
        conn.close()
        
        logger.info("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        return False

# ======================
# Protected Delete Functions
# ======================

@transaction
def delete_session(session_id: int, force_delete: bool = False, 
                  conn=None, cursor=None) -> bool:
    """Ø­Ø°Ù Ø¬Ù„Ø³Ø© - Ù…Ø¹ Ø­Ù…Ø§ÙŠØ© Ø¶Ø¯ Ø§Ù„Ø­Ø°Ù Ø§Ù„Ø¹Ø±Ø¶ÙŠ"""
    try:
        if not force_delete and not FORCE_DELETE:
            logger.critical(f"ğŸš« Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ø°Ù Ø¬Ù„Ø³Ø© {session_id} Ø¨Ø¯ÙˆÙ† Ø¥Ø°Ù† - Ø§Ù„Ø­Ø°Ù Ù…Ø¹Ø·Ù„")
            return False
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ù„Ø³Ø© Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°Ù
        cursor.execute('SELECT * FROM sessions WHERE id = ?', (session_id,))
        session = cursor.fetchone()
        
        if not session:
            logger.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¬Ù„Ø³Ø© Ø¨Ø§Ù„Ø±Ù‚Ù… {session_id}")
            return False
        
        # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°Ù
        cursor.execute('''
            INSERT INTO change_log 
            (table_name, record_id, action, old_data, changed_at)
            VALUES ('sessions', ?, 'DELETE', ?, CURRENT_TIMESTAMP)
        ''', (session_id, json.dumps(dict(session))))
        
        # Ø­Ø°Ù Ø§Ù„Ø¬Ù„Ø³Ø©
        cursor.execute('DELETE FROM sessions WHERE id = ?', (session_id,))
        
        logger.warning(f"âš ï¸ ØªÙ… Ø­Ø°Ù Ø¬Ù„Ø³Ø© {session_id} (Ù‚ÙˆØ© Ø§Ù„Ø­Ø°Ù: {force_delete})")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø§Ù„Ø¬Ù„Ø³Ø©: {e}")
        raise

@transaction
def delete_all_sessions(force_delete: bool = False, 
                       conn=None, cursor=None) -> bool:
    """Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù„Ø³Ø§Øª - Ù…Ø¹ Ø­Ù…Ø§ÙŠØ© Ù…Ø´Ø¯Ø¯Ø©"""
    try:
        if not force_delete or not FORCE_DELETE:
            logger.critical("ğŸš« Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ø¨Ø¯ÙˆÙ† Ø¥Ø°Ù† - Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù…Ø±ÙÙˆØ¶Ø©")
            return False
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°Ù
        cursor.execute('SELECT COUNT(*) as count FROM sessions')
        count_before = cursor.fetchone()['count']
        
        if count_before == 0:
            logger.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø¬Ù„Ø³Ø§Øª Ù„Ø­Ø°ÙÙ‡Ø§")
            return True
        
        # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°Ù
        cursor.execute('SELECT * FROM sessions')
        all_sessions = cursor.fetchall()
        
        for session in all_sessions:
            session_dict = dict(session)
            cursor.execute('''
                INSERT INTO change_log 
                (table_name, record_id, action, old_data, changed_at)
                VALUES ('sessions', ?, 'DELETE_ALL', ?, CURRENT_TIMESTAMP)
            ''', (session_dict['id'], json.dumps(session_dict)))
        
        # Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù„Ø³Ø§Øª
        cursor.execute('DELETE FROM sessions')
        
        # Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
        cursor.execute('DELETE FROM sqlite_sequence WHERE name="sessions"')
        
        logger.warning(f"âš ï¸ ØªÙ… Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù„Ø³Ø§Øª ({count_before} Ø¬Ù„Ø³Ø©) - Ù‡Ø°Ù‡ Ø¹Ù…Ù„ÙŠØ© Ø®Ø·ÙŠØ±Ø©")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù„Ø³Ø§Øª: {e}")
        raise

@transaction
def delete_link(link_id: int, force_delete: bool = False, 
               conn=None, cursor=None) -> bool:
    """Ø­Ø°Ù Ø±Ø§Ø¨Ø· - Ù…Ø¹ Ø­Ù…Ø§ÙŠØ© Ø¶Ø¯ Ø§Ù„Ø­Ø°Ù Ø§Ù„Ø¹Ø±Ø¶ÙŠ"""
    try:
        if not force_delete and not FORCE_DELETE:
            logger.critical(f"ğŸš« Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ø°Ù Ø±Ø§Ø¨Ø· {link_id} Ø¨Ø¯ÙˆÙ† Ø¥Ø°Ù† - Ø§Ù„Ø­Ø°Ù Ù…Ø¹Ø·Ù„")
            return False
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø±Ø§Ø¨Ø· Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°Ù
        cursor.execute('SELECT * FROM links WHERE id = ?', (link_id,))
        link = cursor.fetchone()
        
        if not link:
            logger.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø±Ø§Ø¨Ø· Ø¨Ø§Ù„Ø±Ù‚Ù… {link_id}")
            return False
        
        # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°Ù
        cursor.execute('''
            INSERT INTO change_log 
            (table_name, record_id, action, old_data, changed_at)
            VALUES ('links', ?, 'DELETE', ?, CURRENT_TIMESTAMP)
        ''', (link_id, json.dumps(dict(link))))
        
        # Ø­Ø°Ù Ø§Ù„Ø±Ø§Ø¨Ø·
        cursor.execute('DELETE FROM links WHERE id = ?', (link_id,))
        
        logger.warning(f"âš ï¸ ØªÙ… Ø­Ø°Ù Ø±Ø§Ø¨Ø· {link_id} (Ù‚ÙˆØ© Ø§Ù„Ø­Ø°Ù: {force_delete})")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø§Ù„Ø±Ø§Ø¨Ø·: {e}")
        raise

@transaction
def delete_all_links(force_delete: bool = False, 
                    conn=None, cursor=None) -> bool:
    """Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· - Ù…Ø¹ Ø­Ù…Ø§ÙŠØ© Ù…Ø´Ø¯Ø¯Ø©"""
    try:
        if not force_delete or not FORCE_DELETE:
            logger.critical("ğŸš« Ù…Ø­Ø§ÙˆÙ„Ø© Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¨Ø¯ÙˆÙ† Ø¥Ø°Ù† - Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù…Ø±ÙÙˆØ¶Ø©")
            return False
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°Ù
        cursor.execute('SELECT COUNT(*) as count FROM links')
        count_before = cursor.fetchone()['count']
        
        if count_before == 0:
            logger.info("â„¹ï¸ Ù„Ø§ ØªÙˆØ¬Ø¯ Ø±ÙˆØ§Ø¨Ø· Ù„Ø­Ø°ÙÙ‡Ø§")
            return True
        
        # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°Ù
        cursor.execute('SELECT * FROM links')
        all_links = cursor.fetchall()
        
        for link in all_links:
            link_dict = dict(link)
            cursor.execute('''
                INSERT INTO change_log 
                (table_name, record_id, action, old_data, changed_at)
                VALUES ('links', ?, 'DELETE_ALL', ?, CURRENT_TIMESTAMP)
            ''', (link_dict['id'], json.dumps(link_dict)))
        
        # Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        cursor.execute('DELETE FROM links')
        
        # Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
        cursor.execute('DELETE FROM sqlite_sequence WHERE name="links"')
        
        logger.warning(f"âš ï¸ ØªÙ… Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ({count_before} Ø±Ø§Ø¨Ø·) - Ù‡Ø°Ù‡ Ø¹Ù…Ù„ÙŠØ© Ø®Ø·ÙŠØ±Ø©")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·: {e}")
        raise

# ======================
# Session Management
# ======================

@transaction
def add_session(session_string: str, phone: str = "", user_id: int = 0, 
                username: str = "", display_name: str = "", 
                conn=None, cursor=None) -> bool:
    """Ø¥Ø¶Ø§ÙØ© Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
    try:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¬Ù„Ø³Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹
        cursor.execute(
            "SELECT id FROM sessions WHERE session_string = ?",
            (session_string,)
        )
        existing = cursor.fetchone()
        
        if existing:
            logger.info(f"â„¹ï¸ Ø§Ù„Ø¬Ù„Ø³Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© Ø¨Ø§Ù„ÙØ¹Ù„ Ø¨Ø§Ù„Ø±Ù‚Ù…: {existing['id']}")
            return False
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        cursor.execute('''
            INSERT INTO sessions 
            (session_string, phone_number, user_id, username, display_name, 
             is_active, added_date, last_used)
            VALUES (?, ?, ?, ?, ?, 1, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)
        ''', (session_string, phone, user_id, username, display_name))
        
        session_id = cursor.lastrowid
        
        # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
        cursor.execute('''
            INSERT INTO change_log 
            (table_name, record_id, action, new_data, changed_at)
            VALUES ('sessions', ?, 'CREATE', ?, CURRENT_TIMESTAMP)
        ''', (session_id, json.dumps({
            'session_string': session_string,
            'display_name': display_name
        })))
        
        logger.info(f"âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©: {display_name} (Ø§Ù„Ø±Ù‚Ù…: {session_id})")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø¬Ù„Ø³Ø©: {e}")
        raise

@transaction
def get_sessions(active_only: bool = False, conn=None, cursor=None) -> List[Dict]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ù„Ø³Ø§Øª"""
    try:
        if active_only:
            cursor.execute('''
                SELECT * FROM sessions 
                WHERE is_active = 1 
                ORDER BY added_date DESC
            ''')
        else:
            cursor.execute('''
                SELECT * FROM sessions 
                ORDER BY is_active DESC, added_date DESC
            ''')
        
        return [dict(row) for row in cursor.fetchall()]
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¬Ù„Ø³Ø§Øª: {e}")
        return []

@transaction  
def update_session_status(session_id: int, is_active: bool, conn=None, cursor=None) -> bool:
    """ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©"""
    try:
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
        cursor.execute('SELECT * FROM sessions WHERE id = ?', (session_id,))
        old_session = cursor.fetchone()
        
        if not old_session:
            logger.warning(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¬Ù„Ø³Ø© Ø¨Ø§Ù„Ø±Ù‚Ù… {session_id}")
            return False
        
        # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø­Ø§Ù„Ø©
        cursor.execute('''
            UPDATE sessions 
            SET is_active = ?, last_used = CURRENT_TIMESTAMP,
                updated_at = CURRENT_TIMESTAMP
            WHERE id = ?
        ''', (1 if is_active else 0, session_id))
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        cursor.execute('SELECT * FROM sessions WHERE id = ?', (session_id,))
        new_session = cursor.fetchone()
        
        # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
        cursor.execute('''
            INSERT INTO change_log 
            (table_name, record_id, action, old_data, new_data, changed_at)
            VALUES ('sessions', ?, 'UPDATE', ?, ?, CURRENT_TIMESTAMP)
        ''', (session_id, json.dumps(dict(old_session)), json.dumps(dict(new_session))))
        
        status = "ØªÙ… ØªÙØ¹ÙŠÙ„" if is_active else "ØªÙ… ØªØ¹Ø·ÙŠÙ„"
        logger.info(f"âœ… {status} Ø§Ù„Ø¬Ù„Ø³Ø© {session_id}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©: {e}")
        raise

# ======================
# Link Management
# ======================

@transaction
def add_link(url: str, platform: str, link_type: str, 
             title: str = "", members_count: int = 0, 
             session_id: int = None, description: str = "", 
             metadata: Dict = None, conn=None, cursor=None) -> Tuple[bool, str, Optional[int]]:
    """Ø¥Ø¶Ø§ÙØ© Ø±Ø§Ø¨Ø· Ø¬Ø¯ÙŠØ¯"""
    try:
        url = url.strip()
        
        if not LinkType.is_valid_type(platform, link_type):
            logger.error(f"âŒ Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø· ØºÙŠØ± ØµØ§Ù„Ø­: {platform}/{link_type}")
            return False, "invalid_type", None
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… ØªÙƒØ±Ø§Ø± Ø§Ù„Ø±Ø§Ø¨Ø·
        cursor.execute('SELECT id FROM links WHERE url = ?', (url,))
        existing = cursor.fetchone()
        
        if existing:
            logger.info(f"â„¹ï¸ Ø§Ù„Ø±Ø§Ø¨Ø· Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ø§Ù„ÙØ¹Ù„: {url}")
            return False, "duplicate", existing['id']
        
        # ØªØ­ÙˆÙŠÙ„ metadata Ø¥Ù„Ù‰ JSON
        metadata_json = json.dumps(metadata) if metadata else None
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø¬Ø¯ÙŠØ¯
        cursor.execute('''
            INSERT INTO links 
            (url, platform, link_type, title, description, members_count, 
             collected_at, session_id, metadata, last_checked, checked_count)
            VALUES (?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP, ?, ?, CURRENT_TIMESTAMP, 1)
        ''', (url, platform, link_type, title, description, members_count, 
              session_id, metadata_json))
        
        link_id = cursor.lastrowid
        
        # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª
        cursor.execute('''
            INSERT INTO change_log 
            (table_name, record_id, action, new_data, changed_at)
            VALUES ('links', ?, 'CREATE', ?, CURRENT_TIMESTAMP)
        ''', (link_id, json.dumps({
            'url': url,
            'platform': platform,
            'link_type': link_type,
            'title': title
        })))
        
        logger.info(f"âœ… ØªÙ…Øª Ø¥Ø¶Ø§ÙØ© Ø±Ø§Ø¨Ø·: {url} ({platform}/{link_type})")
        return True, "added", link_id
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¶Ø§ÙØ© Ø±Ø§Ø¨Ø·: {e}")
        raise

@transaction
def update_link_members(link_id: int, members_count: int, conn=None, cursor=None) -> bool:
    """ØªØ­Ø¯ÙŠØ« Ø¹Ø¯Ø¯ Ø£Ø¹Ø¶Ø§Ø¡ Ø§Ù„Ø±Ø§Ø¨Ø·"""
    try:
        cursor.execute('''
            UPDATE links 
            SET members_count = ?, 
                last_checked = CURRENT_TIMESTAMP,
                checked_count = checked_count + 1,
                updated_at = CURRENT_TIMESTAMP
            WHERE id = ?
        ''', (members_count, link_id))
        
        if cursor.rowcount > 0:
            logger.info(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø±Ø§Ø¨Ø· {link_id} Ø¥Ù„Ù‰ {members_count} Ø¹Ø¶Ùˆ")
            return True
        return False
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø£Ø¹Ø¶Ø§Ø¡ Ø§Ù„Ø±Ø§Ø¨Ø·: {e}")
        raise

@transaction
def deactivate_link(link_id: int, reason: str = "", conn=None, cursor=None) -> bool:
    """ØªØ¹Ø·ÙŠÙ„ Ø±Ø§Ø¨Ø·"""
    try:
        cursor.execute('''
            UPDATE links 
            SET is_active = 0,
                description = CASE 
                    WHEN description IS NOT NULL AND description != '' 
                    THEN description || ' | ' || ?
                    ELSE ?
                END,
                updated_at = CURRENT_TIMESTAMP
            WHERE id = ?
        ''', (f"ØªÙ… Ø§Ù„ØªØ¹Ø·ÙŠÙ„: {reason}", f"ØªÙ… Ø§Ù„ØªØ¹Ø·ÙŠÙ„: {reason}", link_id))
        
        if cursor.rowcount > 0:
            logger.info(f"âœ… ØªÙ… ØªØ¹Ø·ÙŠÙ„ Ø±Ø§Ø¨Ø· {link_id}: {reason}")
            return True
        return False
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ¹Ø·ÙŠÙ„ Ø±Ø§Ø¨Ø·: {e}")
        raise

@transaction
def get_links_by_type(platform: str, link_type: str = None,
                      active_only: bool = True, limit: int = 20, 
                      offset: int = 0, conn=None, cursor=None) -> List[Dict]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ© ÙˆØ§Ù„Ù†ÙˆØ¹"""
    try:
        query = '''
            SELECT * FROM links 
            WHERE platform = ?
        '''
        params = [platform]
        
        if link_type:
            query += ' AND link_type = ?'
            params.append(link_type)
        
        if active_only:
            query += ' AND is_active = 1'
        
        query += ' ORDER BY collected_at DESC LIMIT ? OFFSET ?'
        params.extend([limit, offset])
        
        cursor.execute(query, params)
        return [dict(row) for row in cursor.fetchall()]
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹: {e}")
        return []

@transaction
def cleanup_old_links(days_old: int = 30, force_delete: bool = False,
                     conn=None, cursor=None) -> int:
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© Ø§Ù„Ù…Ø¹Ø·Ù„Ø©"""
    try:
        if not force_delete and not FORCE_DELETE:
            logger.critical("ğŸš« Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¨Ø¯ÙˆÙ† Ø¥Ø°Ù† - Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ù…Ø¹Ø·Ù„Ø©")
            return 0
        
        cutoff_date = (datetime.now() - timedelta(days=days_old)).strftime('%Y-%m-%d')
        
        cursor.execute('''
            SELECT COUNT(*) as count FROM links 
            WHERE is_active = 0 
            AND DATE(updated_at) < ?
        ''', (cutoff_date,))
        
        count = cursor.fetchone()['count']
        
        if count > 0:
            # ØªØ³Ø¬ÙŠÙ„ ÙÙŠ Ø³Ø¬Ù„ Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°Ù
            cursor.execute('SELECT * FROM links WHERE is_active = 0 AND DATE(updated_at) < ?', 
                          (cutoff_date,))
            old_links = cursor.fetchall()
            
            for link in old_links:
                link_dict = dict(link)
                cursor.execute('''
                    INSERT INTO change_log 
                    (table_name, record_id, action, old_data, changed_at)
                    VALUES ('links', ?, 'CLEANUP', ?, CURRENT_TIMESTAMP)
                ''', (link_dict['id'], json.dumps(link_dict)))
            
            cursor.execute('''
                DELETE FROM links 
                WHERE is_active = 0 
                AND DATE(updated_at) < ?
            ''', (cutoff_date,))
            
            logger.warning(f"âš ï¸ ØªÙ… ØªÙ†Ø¸ÙŠÙ {count} Ø±Ø§Ø¨Ø· Ù‚Ø¯ÙŠÙ… (Ù‚ÙˆØ© Ø§Ù„Ø­Ø°Ù: {force_delete})")
        
        return count
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©: {e}")
        raise

# ======================
# Statistics & Reporting
# ======================

@transaction
def get_link_stats(conn=None, cursor=None) -> Dict:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙØµÙ„Ø© Ù„Ù„Ø±ÙˆØ§Ø¨Ø·"""
    try:
        stats = {}
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ©
        cursor.execute('''
            SELECT platform, COUNT(*) as count 
            FROM links 
            WHERE is_active = 1 
            GROUP BY platform
        ''')
        stats['by_platform'] = {row['platform']: row['count'] for row in cursor.fetchall()}
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ù…ÙØµÙ„Ø©
        cursor.execute('''
            SELECT 
                link_type,
                COUNT(*) as count
            FROM links 
            WHERE platform = 'telegram' AND is_active = 1 
            GROUP BY link_type
            ORDER BY count DESC
        ''')
        
        telegram_stats = {}
        for row in cursor.fetchall():
            telegram_stats[row['link_type']] = row['count']
        
        stats['telegram_by_type'] = telegram_stats
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§ØªØ³Ø§Ø¨
        cursor.execute('''
            SELECT 
                link_type,
                COUNT(*) as count
            FROM links 
            WHERE platform = 'whatsapp' AND is_active = 1 
            GROUP BY link_type
        ''')
        stats['whatsapp_by_type'] = {row['link_type']: row['count'] for row in cursor.fetchall()}
        
        # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        cursor.execute('SELECT COUNT(*) as total FROM links WHERE is_active = 1')
        stats['total_links'] = cursor.fetchone()['total']
        
        # Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¶Ø§ÙØ© Ø§Ù„ÙŠÙˆÙ…
        cursor.execute('''
            SELECT COUNT(*) as today_count 
            FROM links 
            WHERE DATE(collected_at) = DATE('now') AND is_active = 1
        ''')
        stats['today_links'] = cursor.fetchone()['today_count']
        
        # Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¹Ø·Ù„Ø©
        cursor.execute('SELECT COUNT(*) as inactive FROM links WHERE is_active = 0')
        stats['inactive_links'] = cursor.fetchone()['inactive']
        
        # Ù…ØªÙˆØ³Ø· Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ø¹Ø¶Ø§Ø¡
        cursor.execute('''
            SELECT platform, AVG(members_count) as avg_members
            FROM links 
            WHERE is_active = 1 AND members_count > 0
            GROUP BY platform
        ''')
        stats['avg_members_by_platform'] = {
            row['platform']: round(row['avg_members'], 0) 
            for row in cursor.fetchall()
        }
        
        # Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        cursor.execute('''
            SELECT platform, link_type, COUNT(*) as count
            FROM links
            WHERE is_active = 1
            GROUP BY platform, link_type
            ORDER BY platform, count DESC
        ''')
        stats['by_platform_and_type'] = {}
        for row in cursor.fetchall():
            platform = row['platform']
            link_type = row['link_type']
            if platform not in stats['by_platform_and_type']:
                stats['by_platform_and_type'][platform] = {}
            stats['by_platform_and_type'][platform][link_type] = row['count']
        
        return stats
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª: {e}")
        return {}

# ======================
# Export Functions
# ======================

def export_all_links() -> List[str]:
    """ØªØµØ¯ÙŠØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙÙŠ Ø£Ù‚Ø³Ø§Ù… Ù…Ù†ÙØµÙ„Ø©"""
    try:
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØµØ¯ÙŠØ±
        os.makedirs(EXPORT_DIR, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        export_dir = os.path.join(EXPORT_DIR, f"export_{timestamp}")
        os.makedirs(export_dir, exist_ok=True)
        
        exported_files = []
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
        stats = get_link_stats()
        
        # 1. ØªØµØ¯ÙŠØ± Ø±ÙˆØ§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù… - Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¹Ø§Ù…Ø©
        telegram_public_groups = get_links_by_type('telegram', LinkType.TELEGRAM_PUBLIC_GROUP.value)
        if telegram_public_groups:
            filename = f"telegram_public_groups_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# Telegram Public Groups\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(telegram_public_groups)}\n")
                f.write("=" * 50 + "\n\n")
                for link in telegram_public_groups:
                    f.write(f"{link['url']}\n")
            exported_files.append(filepath)
            logger.info(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± {len(telegram_public_groups)} Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¹Ø§Ù…Ø©")
        
        # 2. ØªØµØ¯ÙŠØ± Ø±ÙˆØ§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù… - Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø®Ø§ØµØ©
        telegram_private_groups = get_links_by_type('telegram', LinkType.TELEGRAM_PRIVATE_GROUP.value)
        if telegram_private_groups:
            filename = f"telegram_private_groups_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# Telegram Private Groups\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(telegram_private_groups)}\n")
                f.write("=" * 50 + "\n\n")
                for link in telegram_private_groups:
                    f.write(f"{link['url']}\n")
            exported_files.append(filepath)
            logger.info(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± {len(telegram_private_groups)} Ù…Ø¬Ù…ÙˆØ¹Ø© Ø®Ø§ØµØ©")
        
        # 3. ØªØµØ¯ÙŠØ± Ø±ÙˆØ§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù… - Ø·Ù„Ø¨ Ø§Ù†Ø¶Ù…Ø§Ù…
        telegram_join_request = get_links_by_type('telegram', LinkType.TELEGRAM_JOIN_REQUEST.value)
        if telegram_join_request:
            filename = f"telegram_join_requests_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# Telegram Join Requests\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(telegram_join_request)}\n")
                f.write("=" * 50 + "\n\n")
                for link in telegram_join_request:
                    f.write(f"{link['url']}\n")
            exported_files.append(filepath)
            logger.info(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± {len(telegram_join_request)} Ø·Ù„Ø¨ Ø§Ù†Ø¶Ù…Ø§Ù…")
        
        # 4. ØªØµØ¯ÙŠØ± Ø±ÙˆØ§Ø¨Ø· ÙˆØ§ØªØ³Ø§Ø¨
        whatsapp_groups = get_links_by_type('whatsapp', LinkType.WHATSAPP_GROUP.value)
        if whatsapp_groups:
            filename = f"whatsapp_groups_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# WhatsApp Groups\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(whatsapp_groups)}\n")
                f.write("=" * 50 + "\n\n")
                for link in whatsapp_groups:
                    f.write(f"{link['url']}\n")
            exported_files.append(filepath)
            logger.info(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± {len(whatsapp_groups)} Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§ØªØ³Ø§Ø¨")
        
        # 5. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¥Ø­ØµØ§Ø¦ÙŠ
        stats_file = os.path.join(export_dir, f"stats_{timestamp}.txt")
        with open(stats_file, 'w', encoding=EXPORT_ENCODING) as f:
            f.write(f"# Export Statistics\n")
            f.write(f"# Generated: {datetime.now()}\n")
            f.write("=" * 50 + "\n\n")
            
            f.write("ğŸ“Š Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø±ÙˆØ§Ø¨Ø·\n")
            f.write("=" * 30 + "\n")
            
            for platform, count in stats.get('by_platform', {}).items():
                f.write(f"\n{platform.upper()}: {count} Ø±Ø§Ø¨Ø·\n")
                
                if platform == 'telegram' and 'telegram_by_type' in stats:
                    for link_type, type_count in stats['telegram_by_type'].items():
                        f.write(f"  â”œâ”€ {link_type}: {type_count}\n")
                
                elif platform == 'whatsapp' and 'whatsapp_by_type' in stats:
                    for link_type, type_count in stats['whatsapp_by_type'].items():
                        f.write(f"  â”œâ”€ {link_type}: {type_count}\n")
            
            f.write(f"\n\nğŸ“ˆ Ù…Ù„Ø®Øµ\n")
            f.write("=" * 30 + "\n")
            f.write(f"Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù†Ø´Ø·Ø©: {stats.get('total_links', 0)}\n")
            f.write(f"Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ÙŠÙˆÙ…: {stats.get('today_links', 0)}\n")
            f.write(f"Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ø·Ù„Ø©: {stats.get('inactive_links', 0)}\n")
        
        exported_files.append(stats_file)
        
        # 6. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù README
        readme_file = os.path.join(export_dir, "README.txt")
        with open(readme_file, 'w', encoding=EXPORT_ENCODING) as f:
            f.write(f"# Export Directory\n")
            f.write(f"# Generated: {datetime.now()}\n")
            f.write("=" * 50 + "\n\n")
            
            f.write("ğŸ“ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ù„ÙØ§Øª:\n")
            f.write("=" * 30 + "\n")
            for file_path in exported_files:
                filename = os.path.basename(file_path)
                f.write(f"- {filename}\n")
            
            f.write(f"\n\nğŸ“Š Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ù…Ù„ÙØ§Øª: {len(exported_files)}\n")
            f.write(f"ğŸ“… ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØµØ¯ÙŠØ±: {datetime.now()}\n")
        
        logger.info(f"âœ… ØªÙ… ØªØµØ¯ÙŠØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¥Ù„Ù‰ {export_dir}")
        return exported_files
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØµØ¯ÙŠØ± Ø§Ù„Ø±ÙˆØ§Ø¨Ø·: {e}")
        return []

# ======================
# Maintenance Functions
# ======================

def run_maintenance():
    """ØªØ´ØºÙŠÙ„ Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø¯ÙˆØ±ÙŠØ©"""
    try:
        logger.info("ğŸ”§ ØªØ´ØºÙŠÙ„ ØµÙŠØ§Ù†Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
        
        # 1. Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©
        backup_path = DatabaseConnection.backup_database()
        if backup_path:
            logger.info(f"ğŸ’¾ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©: {backup_path}")
        
        # 2. ØªØ­Ø³ÙŠÙ† Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        conn = DatabaseConnection.get_connection()
        cursor = conn.cursor()
        
        cursor.execute("PRAGMA optimize")
        cursor.execute("VACUUM")
        conn.commit()
        conn.close()
        
        logger.info("âœ… Ø§ÙƒØªÙ…Ù„Øª ØµÙŠØ§Ù†Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª")
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØµÙŠØ§Ù†Ø©: {e}")

# ======================
# Utility Functions
# ======================

def check_database_health():
    """ÙØ­Øµ ØµØ­Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    try:
        conn = DatabaseConnection.get_connection()
        cursor = conn.cursor()
        
        print("\nğŸ” ÙØ­Øµ ØµØ­Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
        print("=" * 50)
        
        # 1. ÙØ­Øµ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = cursor.fetchall()
        print(f"âœ… Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„: {len(tables)}")
        
        # 2. ÙØ­Øµ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        cursor.execute('''
            SELECT platform, link_type, COUNT(*) as count
            FROM links
            GROUP BY platform, link_type
        ''')
        
        print("\nğŸ“Š Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:")
        total_links = 0
        for row in cursor.fetchall():
            print(f"  {row['platform']}/{row['link_type']}: {row['count']}")
            total_links += row['count']
        
        print(f"\nğŸ“ˆ Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·: {total_links}")
        
        # 3. ÙØ­Øµ Ø§Ù„Ø¬Ù„Ø³Ø§Øª
        cursor.execute("SELECT COUNT(*) as count FROM sessions")
        sessions_count = cursor.fetchone()['count']
        print(f"ğŸ‘¥ Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø§Øª: {sessions_count}")
        
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"âŒ ÙØ­Øµ ØµØ­Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙØ´Ù„: {e}")
        return False

# ======================
# Initialization
# ======================

if __name__ == "__main__":
    print("ğŸ”§ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª...")
    if init_db():
        print("âœ… ØªÙ… ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø¨Ù†Ø¬Ø§Ø­!")
        
        # ÙØ­Øµ ØµØ­Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
        check_database_health()
        
        # ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙŠØ§Ù†Ø© Ø§Ù„Ø£ÙˆÙ„ÙŠØ©
        run_maintenance()
    else:
        print("âŒ ÙØ´Ù„ ÙÙŠ ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª!")
