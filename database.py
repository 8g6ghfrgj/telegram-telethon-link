import sqlite3
import logging
import os
import json
import csv
from datetime import datetime
from typing import List, Dict, Optional, Tuple, Any
import hashlib

from config import DATABASE_PATH, DATA_DIR, EXPORT_DIR, EXPORT_ENCODING

# ======================
# Logging
# ======================

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ======================
# Database Connection
# ======================

def get_db_connection():
    """Ø¥Ù†Ø´Ø§Ø¡ Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ø¹ Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡"""
    try:
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø¬Ù„Ø¯ data
        os.makedirs(os.path.dirname(DATABASE_PATH), exist_ok=True)
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø§ØªØµØ§Ù„
        conn = sqlite3.connect(DATABASE_PATH)
        conn.row_factory = sqlite3.Row
        
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡
        conn.execute('PRAGMA journal_mode = WAL')
        conn.execute('PRAGMA synchronous = NORMAL')
        conn.execute(f'PRAGMA cache_size = -{2000}')  # 2MB
        
        return conn
        
    except Exception as e:
        logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§ØªØµØ§Ù„ Ø¨Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©
        try:
            # Ø­Ø°Ù Ø§Ù„Ù…Ù„Ù Ø§Ù„ØªØ§Ù„Ù Ø¥Ø°Ø§ ÙˆØ¬Ø¯
            if os.path.exists(DATABASE_PATH):
                os.remove(DATABASE_PATH)
                logger.info(f"ğŸ—‘ï¸ ØªÙ… Ø­Ø°Ù Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØªØ§Ù„ÙØ©: {DATABASE_PATH}")
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø¬Ø¯ÙŠØ¯
            os.makedirs(os.path.dirname(DATABASE_PATH), exist_ok=True)
            
            # Ø¥Ù†Ø´Ø§Ø¡ Ø§ØªØµØ§Ù„ Ø¬Ø¯ÙŠØ¯
            conn = sqlite3.connect(DATABASE_PATH)
            conn.row_factory = sqlite3.Row
            
            # ØªÙ‡ÙŠØ¦Ø© Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
            init_db()
            
            logger.info(f"âœ… ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©: {DATABASE_PATH}")
            return conn
            
        except Exception as e2:
            logger.error(f"âŒ ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø¨ÙŠØ§Ù†Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©: {e2}")
            raise

def init_db():
    """ØªÙ‡ÙŠØ¦Ø© Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ÙˆØ¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø¬Ù„Ø³Ø§Øª
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                session_string TEXT NOT NULL UNIQUE,
                phone_number TEXT,
                user_id INTEGER,
                username TEXT,
                display_name TEXT,
                is_active BOOLEAN DEFAULT 1,
                added_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                last_used TIMESTAMP,
                notes TEXT
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS links (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                url TEXT NOT NULL UNIQUE,
                platform TEXT NOT NULL,
                link_type TEXT NOT NULL,
                subtype TEXT,
                title TEXT,
                description TEXT,
                members_count INTEGER DEFAULT 0,
                is_active BOOLEAN DEFAULT 1,
                collected_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                collected_by INTEGER,
                session_id INTEGER,
                metadata TEXT,
                FOREIGN KEY (session_id) REFERENCES sessions (id) ON DELETE SET NULL
            )
        ''')
        
        # Ø¬Ø¯ÙˆÙ„ Ø¬Ù„Ø³Ø§Øª Ø§Ù„Ø¬Ù…Ø¹
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS collection_sessions (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                start_time TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                end_time TIMESTAMP,
                status TEXT DEFAULT 'stopped',
                stats TEXT,
                total_links INTEGER DEFAULT 0,
                duplicate_links INTEGER DEFAULT 0,
                inactive_links INTEGER DEFAULT 0,
                channels_skipped INTEGER DEFAULT 0
            )
        ''')
        
        # ÙÙ‡Ø§Ø±Ø³ Ù„Ù„ØªØ­Ø³ÙŠÙ†
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_links_platform_type ON links(platform, link_type)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_links_subtype ON links(subtype)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_links_collected_at ON links(collected_at DESC)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_sessions_active ON sessions(is_active)')
        cursor.execute('CREATE INDEX IF NOT EXISTS idx_links_url ON links(url)')
        
        conn.commit()
        conn.close()
        
        logger.info("âœ… Database initialized successfully")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Error initializing database: {e}")
        return False

# ======================
# Session Management
# ======================

def add_session(session_string: str, phone: str = "", user_id: int = 0, 
                username: str = "", display_name: str = "") -> bool:
    """Ø¥Ø¶Ø§ÙØ© Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ø¬Ù„Ø³Ø© Ù…ÙˆØ¬ÙˆØ¯Ø© Ù…Ø³Ø¨Ù‚Ø§Ù‹
        cursor.execute(
            "SELECT id FROM sessions WHERE session_string = ?",
            (session_string,)
        )
        existing = cursor.fetchone()
        
        if existing:
            logger.info(f"Session already exists with ID: {existing['id']}")
            conn.close()
            return False
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¬Ù„Ø³Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
        cursor.execute('''
            INSERT INTO sessions 
            (session_string, phone_number, user_id, username, display_name, is_active, added_date)
            VALUES (?, ?, ?, ?, ?, 1, CURRENT_TIMESTAMP)
        ''', (session_string, phone, user_id, username, display_name))
        
        conn.commit()
        session_id = cursor.lastrowid
        conn.close()
        
        logger.info(f"âœ… Added new session: {display_name} (ID: {session_id})")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Error adding session: {e}")
        return False

def get_sessions(active_only: bool = False) -> List[Dict]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ù„Ø³Ø§Øª"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        if active_only:
            cursor.execute('''
                SELECT * FROM sessions 
                WHERE is_active = 1 
                ORDER BY added_date DESC
            ''')
        else:
            cursor.execute('''
                SELECT * FROM sessions 
                ORDER BY is_active DESC, added_date DESC
            ''')
        
        sessions = [dict(row) for row in cursor.fetchall()]
        conn.close()
        return sessions
        
    except Exception as e:
        logger.error(f"âŒ Error getting sessions: {e}")
        return []

def delete_session(session_id: int) -> bool:
    """Ø­Ø°Ù Ø¬Ù„Ø³Ø©"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute('DELETE FROM sessions WHERE id = ?', (session_id,))
        
        conn.commit()
        rows_affected = cursor.rowcount
        conn.close()
        
        if rows_affected > 0:
            logger.info(f"âœ… Deleted session ID: {session_id}")
            return True
        else:
            logger.warning(f"âŒ Session ID {session_id} not found")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Error deleting session: {e}")
        return False

def delete_all_sessions() -> bool:
    """Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù„Ø³Ø§Øª"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¹Ø¯Ø¯ Ø§Ù„Ø¬Ù„Ø³Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø­Ø°Ù
        cursor.execute('SELECT COUNT(*) as count FROM sessions')
        count_before = cursor.fetchone()['count']
        
        # Ø­Ø°Ù Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¬Ù„Ø³Ø§Øª
        cursor.execute('DELETE FROM sessions')
        
        # Ø¥Ø¹Ø§Ø¯Ø© Ø¶Ø¨Ø· Ø§Ù„Ø³Ù„Ø³Ù„Ø© Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠØ©
        cursor.execute('DELETE FROM sqlite_sequence WHERE name="sessions"')
        
        conn.commit()
        conn.close()
        
        logger.info(f"âœ… Deleted all sessions ({count_before} sessions)")
        return True
        
    except Exception as e:
        logger.error(f"âŒ Error deleting all sessions: {e}")
        return False

def update_session_status(session_id: int, is_active: bool) -> bool:
    """ØªØ­Ø¯ÙŠØ« Ø­Ø§Ù„Ø© Ø§Ù„Ø¬Ù„Ø³Ø©"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE sessions 
            SET is_active = ?, last_used = CURRENT_TIMESTAMP 
            WHERE id = ?
        ''', (1 if is_active else 0, session_id))
        
        conn.commit()
        rows_affected = cursor.rowcount
        conn.close()
        
        if rows_affected > 0:
            status = "activated" if is_active else "deactivated"
            logger.info(f"âœ… Session {session_id} {status}")
            return True
        else:
            return False
            
    except Exception as e:
        logger.error(f"âŒ Error updating session status: {e}")
        return False

def update_session_usage(session_id: int):
    """ØªØ­Ø¯ÙŠØ« ÙˆÙ‚Øª Ø¢Ø®Ø± Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù„Ù„Ø¬Ù„Ø³Ø©"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            UPDATE sessions 
            SET last_used = CURRENT_TIMESTAMP 
            WHERE id = ?
        ''', (session_id,))
        
        conn.commit()
        conn.close()
        
    except Exception as e:
        logger.error(f"âŒ Error updating session usage: {e}")

# ======================
# Link Management
# ======================

def add_link(url: str, platform: str, link_type: str, 
             title: str = "", members_count: int = 0, 
             session_id: int = None, subtype: str = None,
             description: str = "", metadata: Dict = None) -> Tuple[bool, str]:
    """Ø¥Ø¶Ø§ÙØ© Ø±Ø§Ø¨Ø· Ø¬Ø¯ÙŠØ¯"""
    try:
        url = url.strip()
        
        conn = get_db_connection()
        cursor = conn.cursor()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¹Ø¯Ù… ØªÙƒØ±Ø§Ø± Ø§Ù„Ø±Ø§Ø¨Ø·
        cursor.execute('SELECT id FROM links WHERE url = ?', (url,))
        existing = cursor.fetchone()
        
        if existing:
            conn.close()
            return False, "duplicate"
        
        # ØªØ­ÙˆÙŠÙ„ metadata Ø¥Ù„Ù‰ JSON Ø¥Ø°Ø§ ÙˆØ¬Ø¯
        metadata_json = json.dumps(metadata) if metadata else None
        
        # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø¬Ø¯ÙŠØ¯
        cursor.execute('''
            INSERT INTO links 
            (url, platform, link_type, subtype, title, description, members_count, collected_at, session_id, metadata)
            VALUES (?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP, ?, ?)
        ''', (url, platform, link_type, subtype, title, description, members_count, session_id, metadata_json))
        
        conn.commit()
        link_id = cursor.lastrowid
        conn.close()
        
        logger.info(f"âœ… Added link: {url} ({platform}/{link_type})")
        return True, "added"
        
    except Exception as e:
        logger.error(f"âŒ Error adding link: {e}")
        return False, f"error: {str(e)}"

def get_links_by_type(platform: str, link_type: str = None, subtype: str = None,
                      limit: int = 20, offset: int = 0) -> List[Dict]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹ ÙˆØ§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ÙØ±Ø¹ÙŠ"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        query = '''
            SELECT * FROM links 
            WHERE platform = ? AND is_active = 1
        '''
        params = [platform]
        
        if link_type:
            query += ' AND link_type = ?'
            params.append(link_type)
        
        if subtype:
            query += ' AND subtype = ?'
            params.append(subtype)
        
        query += ' ORDER BY collected_at DESC LIMIT ? OFFSET ?'
        params.extend([limit, offset])
        
        cursor.execute(query, params)
        links = [dict(row) for row in cursor.fetchall()]
        conn.close()
        return links
        
    except Exception as e:
        logger.error(f"âŒ Error getting links by type: {e}")
        return []

def get_all_links(limit: int = 100, offset: int = 0) -> List[Dict]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT * FROM links 
            WHERE is_active = 1
            ORDER BY collected_at DESC
            LIMIT ? OFFSET ?
        ''', (limit, offset))
        
        links = [dict(row) for row in cursor.fetchall()]
        conn.close()
        return links
        
    except Exception as e:
        logger.error(f"âŒ Error getting all links: {e}")
        return []

def get_link_stats() -> Dict:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙØµÙ„Ø© Ù„Ù„Ø±ÙˆØ§Ø¨Ø·"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        stats = {}
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ©
        cursor.execute('''
            SELECT platform, COUNT(*) as count 
            FROM links 
            WHERE is_active = 1 
            GROUP BY platform
        ''')
        stats['by_platform'] = {row['platform']: row['count'] for row in cursor.fetchall()}
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ù…ÙØµÙ„Ø©
        cursor.execute('''
            SELECT 
                link_type,
                subtype,
                COUNT(*) as count
            FROM links 
            WHERE platform = 'telegram' AND is_active = 1 
            GROUP BY link_type, subtype
            ORDER BY link_type, subtype
        ''')
        
        telegram_stats = {}
        for row in cursor.fetchall():
            link_type = row['link_type']
            subtype = row['subtype'] or 'general'
            if link_type not in telegram_stats:
                telegram_stats[link_type] = {}
            telegram_stats[link_type][subtype] = row['count']
        
        stats['telegram_details'] = telegram_stats
        
        # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§ØªØ³Ø§Ø¨
        cursor.execute('''
            SELECT 
                link_type,
                COUNT(*) as count
            FROM links 
            WHERE platform = 'whatsapp' AND is_active = 1 
            GROUP BY link_type
        ''')
        stats['whatsapp_details'] = {row['link_type']: row['count'] for row in cursor.fetchall()}
        
        # Ø¥Ø¬Ù…Ø§Ù„ÙŠ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        cursor.execute('SELECT COUNT(*) as total FROM links WHERE is_active = 1')
        stats['total_links'] = cursor.fetchone()['total']
        
        # Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¶Ø§ÙØ© Ø§Ù„ÙŠÙˆÙ…
        cursor.execute('''
            SELECT COUNT(*) as today_count 
            FROM links 
            WHERE DATE(collected_at) = DATE('now') AND is_active = 1
        ''')
        stats['today_links'] = cursor.fetchone()['today_count']
        
        # Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        cursor.execute('''
            SELECT platform, link_type, COUNT(*) as count
            FROM links
            WHERE is_active = 1
            GROUP BY platform, link_type
            ORDER BY platform, link_type
        ''')
        stats['by_platform_type'] = {}
        for row in cursor.fetchall():
            platform = row['platform']
            link_type = row['link_type']
            if platform not in stats['by_platform_type']:
                stats['by_platform_type'][platform] = {}
            stats['by_platform_type'][platform][link_type] = row['count']
        
        conn.close()
        return stats
        
    except Exception as e:
        logger.error(f"âŒ Error getting link stats: {e}")
        return {}

def export_all_links(format: str = 'txt') -> List[str]:
    """ØªØµØ¯ÙŠØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙÙŠ Ø£Ù‚Ø³Ø§Ù… Ù…Ù†ÙØµÙ„Ø©"""
    try:
        # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ù…Ø¬Ù„Ø¯ Ø§Ù„ØªØµØ¯ÙŠØ±
        os.makedirs(EXPORT_DIR, exist_ok=True)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        export_dir = os.path.join(EXPORT_DIR, f"export_{timestamp}")
        os.makedirs(export_dir, exist_ok=True)
        
        exported_files = []
        
        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù„Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©
        stats = get_link_stats()
        
        # 1. ØªØµØ¯ÙŠØ± Ø±ÙˆØ§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù… - Ù‚Ù†ÙˆØ§Øª
        telegram_channels = get_links_by_type('telegram', 'channel')
        if telegram_channels:
            filename = f"telegram_channels_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# Telegram Channels\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(telegram_channels)}\n")
                f.write("=" * 50 + "\n\n")
                for link in telegram_channels:
                    f.write(f"{link['url']}\n")
            exported_files.append(filepath)
            logger.info(f"âœ… Exported {len(telegram_channels)} Telegram channels")
        
        # 2. ØªØµØ¯ÙŠØ± Ø±ÙˆØ§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù… - Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø¹Ø§Ù…Ø©
        telegram_public_groups = get_links_by_type('telegram', 'group', 'public')
        if telegram_public_groups:
            filename = f"telegram_public_groups_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# Telegram Public Groups\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(telegram_public_groups)}\n")
                f.write("=" * 50 + "\n\n")
                for link in telegram_public_groups:
                    f.write(f"{link['url']}\n")
            exported_files.append(filepath)
            logger.info(f"âœ… Exported {len(telegram_public_groups)} Telegram public groups")
        
        # 3. ØªØµØ¯ÙŠØ± Ø±ÙˆØ§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù… - Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø®Ø§ØµØ©
        telegram_private_groups = get_links_by_type('telegram', 'group', 'private')
        if telegram_private_groups:
            filename = f"telegram_private_groups_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# Telegram Private Groups\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(telegram_private_groups)}\n")
                f.write("=" * 50 + "\n\n")
                for link in telegram_private_groups:
                    f.write(f"{link['url']}\n")
            exported_files.append(filepath)
            logger.info(f"âœ… Exported {len(telegram_private_groups)} Telegram private groups")
        
        # 4. ØªØµØ¯ÙŠØ± Ø±ÙˆØ§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù… - Ø·Ù„Ø¨ Ø§Ù†Ø¶Ù…Ø§Ù…
        telegram_join_request = get_links_by_type('telegram', 'join_request')
        if telegram_join_request:
            filename = f"telegram_join_requests_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# Telegram Join Requests\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(telegram_join_request)}\n")
                f.write("=" * 50 + "\n\n")
                for link in telegram_join_request:
                    f.write(f"{link['url']}\n")
            exported_files.append(filepath)
            logger.info(f"âœ… Exported {len(telegram_join_request)} Telegram join requests")
        
        # 5. ØªØµØ¯ÙŠØ± Ø±ÙˆØ§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù… - Ø¨ÙˆØªØ§Øª
        telegram_bots = get_links_by_type('telegram', 'bot')
        if telegram_bots:
            filename = f"telegram_bots_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# Telegram Bots\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(telegram_bots)}\n")
                f.write("=" * 50 + "\n\n")
                for link in telegram_bots:
                    f.write(f"{link['url']}\n")
            exported_files.append(filepath)
            logger.info(f"âœ… Exported {len(telegram_bots)} Telegram bots")
        
        # 6. ØªØµØ¯ÙŠØ± Ø¬Ù…ÙŠØ¹ Ø±ÙˆØ§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù…
        all_telegram = get_links_by_type('telegram', limit=10000)
        if all_telegram:
            filename = f"telegram_all_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# All Telegram Links\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(all_telegram)}\n")
                f.write("=" * 50 + "\n\n")
                for link in all_telegram:
                    link_type = link['link_type']
                    subtype = link['subtype'] or ''
                    if subtype:
                        f.write(f"# [{link_type}/{subtype}]\n")
                    else:
                        f.write(f"# [{link_type}]\n")
                    f.write(f"{link['url']}\n\n")
            exported_files.append(filepath)
            logger.info(f"âœ… Exported {len(all_telegram)} total Telegram links")
        
        # 7. ØªØµØ¯ÙŠØ± Ø±ÙˆØ§Ø¨Ø· ÙˆØ§ØªØ³Ø§Ø¨
        whatsapp_groups = get_links_by_type('whatsapp', 'group')
        if whatsapp_groups:
            filename = f"whatsapp_groups_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# WhatsApp Groups\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(whatsapp_groups)}\n")
                f.write("=" * 50 + "\n\n")
                for link in whatsapp_groups:
                    f.write(f"{link['url']}\n")
            exported_files.append(filepath)
            logger.info(f"âœ… Exported {len(whatsapp_groups)} WhatsApp groups")
        
        # 8. ØªØµØ¯ÙŠØ± Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙÙŠ Ù…Ù„Ù ÙˆØ§Ø­Ø¯
        all_links = get_all_links(limit=10000)
        if all_links:
            filename = f"all_platforms_{timestamp}.txt"
            filepath = os.path.join(export_dir, filename)
            with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
                f.write(f"# All Links - All Platforms\n")
                f.write(f"# Exported: {datetime.now()}\n")
                f.write(f"# Total: {len(all_links)}\n")
                f.write("=" * 50 + "\n\n")
                
                current_platform = None
                current_type = None
                
                for link in all_links:
                    platform = link['platform']
                    link_type = link['link_type']
                    subtype = link['subtype'] or ''
                    
                    if platform != current_platform:
                        f.write(f"\n{'='*50}\n")
                        f.write(f"# {platform.upper()} LINKS\n")
                        f.write(f"{'='*50}\n\n")
                        current_platform = platform
                        current_type = None
                    
                    type_label = f"{link_type}"
                    if subtype:
                        type_label += f" ({subtype})"
                    
                    if type_label != current_type:
                        f.write(f"\n## {type_label}\n")
                        current_type = type_label
                    
                    f.write(f"{link['url']}\n")
            
            exported_files.append(filepath)
            logger.info(f"âœ… Exported {len(all_links)} total links from all platforms")
        
        # 9. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù Ø¥Ø­ØµØ§Ø¦ÙŠ
        stats_file = os.path.join(export_dir, f"stats_{timestamp}.txt")
        with open(stats_file, 'w', encoding=EXPORT_ENCODING) as f:
            f.write(f"# Export Statistics\n")
            f.write(f"# Generated: {datetime.now()}\n")
            f.write("=" * 50 + "\n\n")
            
            f.write("ğŸ“Š LINK STATISTICS\n")
            f.write("=" * 30 + "\n")
            
            for platform, count in stats.get('by_platform', {}).items():
                f.write(f"\n{platform.upper()}: {count} links\n")
                
                if platform == 'telegram' and 'telegram_details' in stats:
                    for link_type, subtypes in stats['telegram_details'].items():
                        f.write(f"  â””â”€ {link_type}:\n")
                        for subtype, subcount in subtypes.items():
                            f.write(f"      â”œâ”€ {subtype}: {subcount}\n")
                
                elif platform == 'whatsapp' and 'whatsapp_details' in stats:
                    for link_type, count_type in stats['whatsapp_details'].items():
                        f.write(f"  â””â”€ {link_type}: {count_type}\n")
            
            f.write(f"\n\nğŸ“ˆ SUMMARY\n")
            f.write("=" * 30 + "\n")
            f.write(f"Total Links: {stats.get('total_links', 0)}\n")
            f.write(f"Today's Links: {stats.get('today_links', 0)}\n")
        
        exported_files.append(stats_file)
        
        # 10. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù„Ù README
        readme_file = os.path.join(export_dir, "README.txt")
        with open(readme_file, 'w', encoding=EXPORT_ENCODING) as f:
            f.write(f"# Export Directory\n")
            f.write(f"# Generated: {datetime.now()}\n")
            f.write("=" * 50 + "\n\n")
            
            f.write("ğŸ“ FILE LIST:\n")
            f.write("=" * 30 + "\n")
            for file_path in exported_files:
                filename = os.path.basename(file_path)
                f.write(f"- {filename}\n")
            
            f.write(f"\n\nğŸ“Š TOTAL FILES: {len(exported_files)}\n")
            f.write(f"ğŸ“… EXPORT DATE: {datetime.now()}\n")
        
        logger.info(f"âœ… Exported all links to {export_dir}")
        return exported_files
        
    except Exception as e:
        logger.error(f"âŒ Error exporting all links: {e}")
        return []

def export_links_by_type(platform: str, link_type: str = None, subtype: str = None, 
                         format: str = 'txt') -> str:
    """ØªØµØ¯ÙŠØ± Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ© ÙˆØ§Ù„Ù†ÙˆØ¹ ÙˆØ§Ù„ØªØµÙ†ÙŠÙ Ø§Ù„ÙØ±Ø¹ÙŠ"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        query = '''
            SELECT url, title, members_count, collected_at FROM links 
            WHERE platform = ? AND is_active = 1
        '''
        params = [platform]
        
        if link_type:
            query += ' AND link_type = ?'
            params.append(link_type)
        
        if subtype:
            query += ' AND subtype = ?'
            params.append(subtype)
        
        query += ' ORDER BY collected_at DESC'
        
        cursor.execute(query, params)
        links = cursor.fetchall()
        conn.close()
        
        if not links:
            return None
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if link_type and subtype:
            filename = f"{platform}_{link_type}_{subtype}_{timestamp}.txt"
        elif link_type:
            filename = f"{platform}_{link_type}_{timestamp}.txt"
        else:
            filename = f"{platform}_all_{timestamp}.txt"
        
        filepath = os.path.join(EXPORT_DIR, filename)
        
        # ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¥Ù„Ù‰ Ø§Ù„Ù…Ù„Ù
        with open(filepath, 'w', encoding=EXPORT_ENCODING) as f:
            f.write(f"# Exported at: {datetime.now()}\n")
            f.write(f"# Platform: {platform}\n")
            if link_type:
                f.write(f"# Type: {link_type}\n")
            if subtype:
                f.write(f"# Subtype: {subtype}\n")
            f.write(f"# Total links: {len(links)}\n")
            f.write("=" * 50 + "\n\n")
            
            for link in links:
                f.write(f"{link['url']}\n")
                if link['title']:
                    f.write(f"# Title: {link['title']}\n")
                if link['members_count'] > 0:
                    f.write(f"# Members: {link['members_count']}\n")
                f.write(f"# Collected: {link['collected_at']}\n")
                f.write("\n")
        
        logger.info(f"âœ… Exported {len(links)} links to {filepath}")
        return filepath
        
    except Exception as e:
        logger.error(f"âŒ Export error: {e}")
        return None

def export_to_csv(platform: str = None, link_type: str = None) -> str:
    """ØªØµØ¯ÙŠØ± Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¥Ù„Ù‰ Ù…Ù„Ù CSV"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        if platform:
            if link_type:
                cursor.execute('''
                    SELECT url, platform, link_type, subtype, title, 
                           members_count, collected_at 
                    FROM links 
                    WHERE platform = ? AND link_type = ? AND is_active = 1
                    ORDER BY collected_at DESC
                ''', (platform, link_type))
            else:
                cursor.execute('''
                    SELECT url, platform, link_type, subtype, title, 
                           members_count, collected_at 
                    FROM links 
                    WHERE platform = ? AND is_active = 1
                    ORDER BY collected_at DESC
                ''', (platform,))
        else:
            cursor.execute('''
                SELECT url, platform, link_type, subtype, title, 
                       members_count, collected_at 
                FROM links 
                WHERE is_active = 1
                ORDER BY platform, link_type, collected_at DESC
            ''')
        
        links = cursor.fetchall()
        conn.close()
        
        if not links:
            return None
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        if platform and link_type:
            filename = f"{platform}_{link_type}_{timestamp}.csv"
        elif platform:
            filename = f"{platform}_{timestamp}.csv"
        else:
            filename = f"all_links_{timestamp}.csv"
        
        filepath = os.path.join(EXPORT_DIR, filename)
        
        # ÙƒØªØ§Ø¨Ø© Ø¥Ù„Ù‰ CSV
        with open(filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:
            fieldnames = ['url', 'platform', 'link_type', 'subtype', 'title', 
                         'members_count', 'collected_at']
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            
            writer.writeheader()
            for link in links:
                writer.writerow(dict(link))
        
        logger.info(f"âœ… Exported {len(links)} links to CSV: {filepath}")
        return filepath
        
    except Exception as e:
        logger.error(f"âŒ CSV export error: {e}")
        return None

# ======================
# Collection Sessions
# ======================

def start_collection_session() -> int:
    """Ø¨Ø¯Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ù…Ø¹ Ø¬Ø¯ÙŠØ¯Ø©"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO collection_sessions 
            (start_time, status) 
            VALUES (CURRENT_TIMESTAMP, 'in_progress')
        ''')
        
        conn.commit()
        session_id = cursor.lastrowid
        conn.close()
        
        logger.info(f"âœ… Started collection session ID: {session_id}")
        return session_id
        
    except Exception as e:
        logger.error(f"âŒ Error starting collection session: {e}")
        return 0

def update_collection_stats(session_id: int, stats: Dict):
    """ØªØ­Ø¯ÙŠØ« Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø¬Ù„Ø³Ø© Ø§Ù„Ø¬Ù…Ø¹"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        stats_json = json.dumps(stats)
        
        cursor.execute('''
            UPDATE collection_sessions 
            SET stats = ?, 
                total_links = ?,
                duplicate_links = ?,
                inactive_links = ?,
                channels_skipped = ?
            WHERE id = ?
        ''', (
            stats_json,
            stats.get('total_collected', 0),
            stats.get('duplicate_links', 0),
            stats.get('inactive_links', 0),
            stats.get('channels_skipped', 0),
            session_id
        ))
        
        conn.commit()
        conn.close()
        
        logger.info(f"âœ… Updated collection session {session_id} stats")
        
    except Exception as e:
        logger.error(f"âŒ Error updating collection stats: {e}")

def get_active_collection_session() -> Optional[int]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø¬Ù„Ø³Ø© Ø§Ù„Ø¬Ù…Ø¹ Ø§Ù„Ù†Ø´Ø·Ø©"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT id FROM collection_sessions 
            WHERE status = 'in_progress' 
            ORDER BY start_time DESC 
            LIMIT 1
        ''')
        
        result = cursor.fetchone()
        conn.close()
        
        if result:
            return result['id']
        return None
        
    except Exception as e:
        logger.error(f"âŒ Error getting active collection session: {e}")
        return None

def end_collection_session(session_id: int, status: str = "completed"):
    """Ø¥Ù†Ù‡Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø§Ù„Ø¬Ù…Ø¹"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        cursor.execute('''
            UPDATE collection_sessions
            SET end_time = CURRENT_TIMESTAMP,
                status = ?
            WHERE id = ?
        ''', (status, session_id))

        conn.commit()
        conn.close()

        logger.info(f"âœ… Ended collection session ID: {session_id}")

    except Exception as e:
        logger.error(f"âŒ Error ending collection session: {e}")

# ======================
# Utility Functions
# ======================

def search_links(keyword: str, platform: str = None) -> List[Dict]:
    """Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        query = '''
            SELECT * FROM links 
            WHERE (url LIKE ? OR title LIKE ? OR description LIKE ?) 
            AND is_active = 1
        '''
        params = [f"%{keyword}%", f"%{keyword}%", f"%{keyword}%"]
        
        if platform:
            query += ' AND platform = ?'
            params.append(platform)
        
        query += ' ORDER BY collected_at DESC LIMIT 100'
        
        cursor.execute(query, params)
        links = [dict(row) for row in cursor.fetchall()]
        conn.close()
        return links
        
    except Exception as e:
        logger.error(f"âŒ Search error: {e}")
        return []

def delete_link(link_id: int) -> bool:
    """Ø­Ø°Ù Ø±Ø§Ø¨Ø·"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute('DELETE FROM links WHERE id = ?', (link_id,))
        
        conn.commit()
        rows_affected = cursor.rowcount
        conn.close()
        
        if rows_affected > 0:
            logger.info(f"âœ… Deleted link ID: {link_id}")
            return True
        else:
            logger.warning(f"âŒ Link ID {link_id} not found")
            return False
            
    except Exception as e:
        logger.error(f"âŒ Error deleting link: {e}")
        return False

def get_recent_links(limit: int = 20) -> List[Dict]:
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø­Ø¯Ø« Ø§Ù„Ø±ÙˆØ§Ø¨Ø·"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT * FROM links 
            WHERE is_active = 1
            ORDER BY collected_at DESC
            LIMIT ?
        ''', (limit,))
        
        links = [dict(row) for row in cursor.fetchall()]
        conn.close()
        return links
        
    except Exception as e:
        logger.error(f"âŒ Error getting recent links: {e}")
        return []

# ======================
# Initialization
# ======================

if __name__ == "__main__":
    print("ğŸ”§ Initializing database...")
    if init_db():
        print("âœ… Database initialized successfully!")
    else:
        print("âŒ Failed to initialize database!")
