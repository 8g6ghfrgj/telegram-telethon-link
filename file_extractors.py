import os
import tempfile
import logging
from typing import List, Set
import asyncio

from telethon import TelegramClient
from telethon.tl.types import Message

from link_utils import URL_REGEX

# ======================
# Logging
# ======================

logger = logging.getLogger(__name__)

# ======================
# Constants
# ======================

SUPPORTED_EXTENSIONS = {
    '.pdf': 'application/pdf',
    '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    '.txt': 'text/plain',
    '.rtf': 'application/rtf',
}

MAX_FILE_SIZE = 50 * 1024 * 1024  # 50MB

# ======================
# Public API
# ======================

async def extract_links_from_file(
    client: TelegramClient,
    message: Message
) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ù…Ù„ÙØ§Øª Ù…ØªÙ†ÙˆØ¹Ø©
    ÙŠØ¯Ø¹Ù…: PDF, DOCX, TXT, RTF
    """
    if not message.file:
        return []
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
    if message.file.size > MAX_FILE_SIZE:
        logger.warning(f"File too large: {message.file.size} bytes")
        return []
    
    filename = message.file.name or "file"
    mime_type = message.file.mime_type or ""
    file_ext = os.path.splitext(filename.lower())[1]
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù† Ø§Ù„Ù…Ù„Ù Ù…Ø¯Ø¹ÙˆÙ…
    if file_ext not in SUPPORTED_EXTENSIONS and mime_type not in SUPPORTED_EXTENSIONS.values():
        logger.debug(f"Unsupported file type: {filename} ({mime_type})")
        return []
    
    links: Set[str] = set()
    
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            path = os.path.join(tmpdir, filename)
            
            # ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù
            logger.info(f"Downloading file: {filename}")
            await client.download_media(message, path)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
            if file_ext == '.pdf' or mime_type == 'application/pdf':
                file_links = await _extract_from_pdf_async(path)
            elif file_ext == '.docx' or 'wordprocessingml.document' in mime_type:
                file_links = await _extract_from_docx_async(path)
            elif file_ext == '.txt' or mime_type == 'text/plain':
                file_links = await _extract_from_txt_async(path)
            elif file_ext == '.rtf' or mime_type == 'application/rtf':
                file_links = await _extract_from_rtf_async(path)
            else:
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙ…Ù„Ù Ù†ØµÙŠ Ø¹Ø§Ù…
                file_links = await _extract_generic_text_async(path)
            
            # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
            for link in file_links:
                links.add(link)
            
            logger.info(f"Extracted {len(links)} links from file: {filename}")
            
    except Exception as e:
        logger.error(f"Error extracting links from file {filename}: {e}")
    
    return list(links)

# ======================
# PDF Extraction
# ======================

async def _extract_from_pdf_async(path: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
    try:
        return await asyncio.get_event_loop().run_in_executor(
            None, _extract_from_pdf_sync, path
        )
    except Exception as e:
        logger.error(f"PDF extraction error: {e}")
        return []

def _extract_from_pdf_sync(path: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† PDF (Ù…ØªØ²Ø§Ù…Ù†)"""
    links: Set[str] = set()
    
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… PyPDF2 Ø£ÙˆÙ„Ø§Ù‹
        try:
            from PyPDF2 import PdfReader
            
            reader = PdfReader(path)
            for page in reader.pages:
                text = page.extract_text() or ""
                links.update(URL_REGEX.findall(text))
            
            if links:
                return list(links)
        
        except ImportError:
            logger.warning("PyPDF2 not installed, trying alternatives")
        except Exception as e:
            logger.warning(f"PyPDF2 failed: {e}")
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… pdfplumber ÙƒØ¨Ø¯ÙŠÙ„
        try:
            import pdfplumber
            
            with pdfplumber.open(path) as pdf:
                for page in pdf.pages:
                    text = page.extract_text() or ""
                    links.update(URL_REGEX.findall(text))
        
        except ImportError:
            logger.warning("pdfplumber not installed")
        except Exception as e:
            logger.warning(f"pdfplumber failed: {e}")
    
    except Exception as e:
        logger.error(f"PDF extraction failed: {e}")
    
    return list(links)

# ======================
# DOCX Extraction
# ======================

async def _extract_from_docx_async(path: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† DOCX Ø¨Ø´ÙƒÙ„ ØºÙŠØ± Ù…ØªØ²Ø§Ù…Ù†"""
    try:
        return await asyncio.get_event_loop().run_in_executor(
            None, _extract_from_docx_sync, path
        )
    except Exception as e:
        logger.error(f"DOCX extraction error: {e}")
        return []

def _extract_from_docx_sync(path: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† DOCX (Ù…ØªØ²Ø§Ù…Ù†)"""
    links: Set[str] = set()
    
    try:
        from docx import Document
        
        doc = Document(path)
        
        # ÙÙ‚Ø±Ø§Øª
        for para in doc.paragraphs:
            if para.text:
                links.update(URL_REGEX.findall(para.text))
        
        # Ø¬Ø¯Ø§ÙˆÙ„
        for table in doc.tables:
            for row in table.rows:
                for cell in row.cells:
                    if cell.text:
                        links.update(URL_REGEX.findall(cell.text))
    
    except ImportError:
        logger.warning("python-docx not installed")
    except Exception as e:
        logger.error(f"DOCX extraction failed: {e}")
    
    return list(links)

# ======================
# Text File Extraction
# ======================

async def _extract_from_txt_async(path: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„Ù Ù†ØµÙŠ"""
    try:
        return await asyncio.get_event_loop().run_in_executor(
            None, _extract_from_txt_sync, path
        )
    except Exception as e:
        logger.error(f"TXT extraction error: {e}")
        return []

def _extract_from_txt_sync(path: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„Ù Ù†ØµÙŠ (Ù…ØªØ²Ø§Ù…Ù†)"""
    links: Set[str] = set()
    
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© ÙØªØ­ Ø§Ù„Ù…Ù„Ù Ø¨ØªØ´ÙÙŠØ±Ø§Øª Ù…Ø®ØªÙ„ÙØ©
        encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1256', 'windows-1256']
        
        for encoding in encodings:
            try:
                with open(path, 'r', encoding=encoding) as f:
                    content = f.read()
                    links.update(URL_REGEX.findall(content))
                break  # Ù†Ø¬Ø­ØŒ ØªÙˆÙ‚Ù Ø¹Ù† Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
            except UnicodeDecodeError:
                continue
            except Exception as e:
                logger.warning(f"Failed to read with encoding {encoding}: {e}")
    
    except Exception as e:
        logger.error(f"TXT extraction failed: {e}")
    
    return list(links)

# ======================
# RTF Extraction
# ======================

async def _extract_from_rtf_async(path: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† RTF"""
    try:
        return await asyncio.get_event_loop().run_in_executor(
            None, _extract_from_rtf_sync, path
        )
    except Exception as e:
        logger.error(f"RTF extraction error: {e}")
        return []

def _extract_from_rtf_sync(path: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† RTF (Ù…ØªØ²Ø§Ù…Ù†)"""
    links: Set[str] = set()
    
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… striprtf
        try:
            from striprtf.striprtf import rtf_to_text
            
            with open(path, 'r', encoding='utf-8') as f:
                rtf_content = f.read()
                text_content = rtf_to_text(rtf_content)
                links.update(URL_REGEX.findall(text_content))
        
        except ImportError:
            logger.warning("striprtf not installed, trying basic extraction")
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø³ÙŠØ· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… regex
            with open(path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†ØµÙˆØµ ÙÙŠ RTF
                import re
                text_matches = re.findall(r'\\\'(..)|([a-zA-Z0-9\s,.!?]+)', content)
                extracted_text = ' '.join([''.join(match) for match in text_matches])
                links.update(URL_REGEX.findall(extracted_text))
    
    except Exception as e:
        logger.error(f"RTF extraction failed: {e}")
    
    return list(links)

# ======================
# Generic Text Extraction
# ======================

async def _extract_generic_text_async(path: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ø¹Ø§Ù… Ù…Ù† Ø£ÙŠ Ù…Ù„Ù"""
    try:
        return await asyncio.get_event_loop().run_in_executor(
            None, _extract_generic_text_sync, path
        )
    except Exception as e:
        logger.error(f"Generic text extraction error: {e}")
        return []

def _extract_generic_text_sync(path: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ø¹Ø§Ù… (Ù…ØªØ²Ø§Ù…Ù†)"""
    links: Set[str] = set()
    
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù ÙƒÙ†Øµ Ø«Ù†Ø§Ø¦ÙŠ
        with open(path, 'rb') as f:
            content = f.read()
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± ÙƒÙ†Øµ
            try:
                text = content.decode('utf-8', errors='ignore')
                links.update(URL_REGEX.findall(text))
            except:
                # Ø§Ù„Ø¨Ø­Ø« Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù† Ø£Ù†Ù…Ø§Ø· URLs ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ©
                import re
                url_pattern = rb'https?://[^\x00-\x1F\x7F-\xFF<>"\s]+'
                binary_matches = re.findall(url_pattern, content)
                
                for match in binary_matches:
                    try:
                        url = match.decode('utf-8', errors='ignore')
                        links.add(url)
                    except:
                        pass
    
    except Exception as e:
        logger.error(f"Generic text extraction failed: {e}")
    
    return list(links)

# ======================
# Helper Functions
# ======================

def is_file_supported(filename: str, mime_type: str = "") -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù Ù…Ø¯Ø¹ÙˆÙ…Ù‹Ø§"""
    file_ext = os.path.splitext(filename.lower())[1]
    
    if file_ext in SUPPORTED_EXTENSIONS:
        return True
    
    if mime_type in SUPPORTED_EXTENSIONS.values():
        return True
    
    return False

# ======================
# Quick Test
# ======================

if __name__ == "__main__":
    import sys
    
    print("ğŸ§ª Testing file extractors...")
    print(f"Supported extensions: {list(SUPPORTED_EXTENSIONS.keys())}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ø¹Ù… Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª
    print("\nğŸ“š Checking required libraries:")
    
    libraries = {
        'PyPDF2': 'PyPDF2',
        'python-docx': 'docx',
        'pdfplumber': 'pdfplumber',
        'striprtf': 'striprtf'
    }
    
    for lib_name, import_name in libraries.items():
        try:
            __import__(import_name)
            print(f"  âœ… {lib_name} is installed")
        except ImportError:
            print(f"  âš ï¸  {lib_name} is NOT installed (optional)")
    
    print("\nâœ… File extractors module is ready!")
