import os
import re
import tempfile
import logging
import asyncio
from typing import List, Set, Dict, Optional
from pathlib import Path

from telethon import TelegramClient
from telethon.tl.types import Message

from config import BASE_DIR
from link_utils import extract_links_from_text, clean_link, is_allowed_link

# ======================
# Logging Configuration
# ======================

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ======================
# Constants
# ======================

# Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
SUPPORTED_EXTENSIONS = {
    '.pdf': 'PDF Document',
    '.docx': 'Word Document',
    '.txt': 'Text File',
    '.rtf': 'Rich Text Format',
    '.odt': 'OpenDocument Text',
    '.doc': 'Old Word Document',
}

# Ø£Ù†ÙˆØ§Ø¹ MIME Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
SUPPORTED_MIME_TYPES = {
    'application/pdf': 'PDF',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': 'DOCX',
    'application/msword': 'DOC',
    'text/plain': 'TXT',
    'application/rtf': 'RTF',
    'application/vnd.oasis.opendocument.text': 'ODT',
}

# Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù (50 Ù…ÙŠØ¬Ø§Ø¨Ø§ÙŠØª)
MAX_FILE_SIZE = 50 * 1024 * 1024

# Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ø¯Ù†Ù‰ Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù (100 Ø¨Ø§ÙŠØª)
MIN_FILE_SIZE = 100

# Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ù„ÙØ§Øª ØºÙŠØ± Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
UNSUPPORTED_PATTERNS = [
    r'\.exe$', r'\.dll$', r'\.bat$', r'\.sh$', r'\.py$',
    r'\.zip$', r'\.rar$', r'\.7z$', r'\.tar$', r'\.gz$',
]

# ======================
# Helper Functions
# ======================

def is_file_supported(filename: str, mime_type: str = None) -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù Ù…Ø¯Ø¹ÙˆÙ…Ø§Ù‹
    
    Args:
        filename: Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
        mime_type: Ù†ÙˆØ¹ MIME (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        
    Returns:
        bool: True Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…Ù„Ù Ù…Ø¯Ø¹ÙˆÙ…Ø§Ù‹
    """
    if not filename:
        return False
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· ØºÙŠØ± Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©
    filename_lower = filename.lower()
    for pattern in UNSUPPORTED_PATTERNS:
        if re.search(pattern, filename_lower):
            return False
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ù…ØªØ¯Ø§Ø¯
    file_ext = os.path.splitext(filename_lower)[1]
    if file_ext in SUPPORTED_EXTENSIONS:
        return True
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù†ÙˆØ¹ MIME
    if mime_type and mime_type in SUPPORTED_MIME_TYPES:
        return True
    
    return False

def is_file_size_valid(file_size: int) -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
    
    Args:
        file_size: Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù Ø¨Ø§Ù„Ø¨Ø§ÙŠØª
        
    Returns:
        bool: True Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø­Ø¬Ù… Ù…Ù‚Ø¨ÙˆÙ„Ø§Ù‹
    """
    if not file_size:
        return False
    
    return MIN_FILE_SIZE <= file_size <= MAX_FILE_SIZE

def get_file_type(filename: str, mime_type: str = None) -> str:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
    
    Args:
        filename: Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
        mime_type: Ù†ÙˆØ¹ MIME
        
    Returns:
        str: Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
    """
    if not filename:
        return "unknown"
    
    filename_lower = filename.lower()
    file_ext = os.path.splitext(filename_lower)[1]
    
    if file_ext in SUPPORTED_EXTENSIONS:
        return SUPPORTED_EXTENSIONS[file_ext]
    
    if mime_type and mime_type in SUPPORTED_MIME_TYPES:
        return SUPPORTED_MIME_TYPES[mime_type]
    
    return "unknown"

# ======================
# Main Extraction Function
# ======================

async def extract_links_from_file(
    client: TelegramClient,
    message: Message
) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ù…Ù„Ù
    
    Args:
        client: Ø¹Ù…ÙŠÙ„ Telethon
        message: Ø±Ø³Ø§Ù„Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ù…Ù„Ù
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
    """
    if not message or not message.file:
        logger.debug("No file in message")
        return []
    
    try:
        filename = message.file.name or "unknown"
        file_size = message.file.size or 0
        mime_type = message.file.mime_type or ""
        
        logger.info(f"Processing file: {filename} ({file_size} bytes, {mime_type})")
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¯Ø¹Ù… Ø§Ù„Ù…Ù„Ù
        if not is_file_supported(filename, mime_type):
            logger.warning(f"Unsupported file type: {filename} ({mime_type})")
            return []
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø­Ø¬Ù… Ø§Ù„Ù…Ù„Ù
        if not is_file_size_valid(file_size):
            logger.warning(f"Invalid file size: {file_size} bytes")
            return []
        
        file_type = get_file_type(filename, mime_type)
        logger.info(f"Extracting from {file_type}: {filename}")
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
        links = await _extract_by_file_type(client, message, filename, file_type)
        
        logger.info(f"Extracted {len(links)} links from {filename}")
        return links
        
    except Exception as e:
        logger.error(f"Error extracting links from file: {e}")
        return []

async def _extract_by_file_type(
    client: TelegramClient,
    message: Message,
    filename: str,
    file_type: str
) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­Ø³Ø¨ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
    
    Args:
        client: Ø¹Ù…ÙŠÙ„ Telethon
        message: Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        filename: Ø§Ø³Ù… Ø§Ù„Ù…Ù„Ù
        file_type: Ù†ÙˆØ¹ Ø§Ù„Ù…Ù„Ù
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    """
    filename_lower = filename.lower()
    
    if filename_lower.endswith('.pdf') or file_type == 'PDF':
        return await _extract_from_pdf(client, message)
    
    elif filename_lower.endswith('.docx') or file_type in ['DOCX', 'Word Document']:
        return await _extract_from_docx(client, message)
    
    elif filename_lower.endswith('.doc') or file_type == 'DOC':
        return await _extract_from_doc(client, message)
    
    elif filename_lower.endswith('.txt') or file_type == 'TXT':
        return await _extract_from_txt(client, message)
    
    elif filename_lower.endswith('.rtf') or file_type == 'RTF':
        return await _extract_from_rtf(client, message)
    
    elif filename_lower.endswith('.odt') or file_type == 'ODT':
        return await _extract_from_odt(client, message)
    
    else:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙ…Ù„Ù Ù†ØµÙŠ Ø¹Ø§Ù…
        return await _extract_generic(client, message)

# ======================
# PDF Extraction
# ======================

async def _extract_from_pdf(client: TelegramClient, message: Message) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ù…Ù„Ù PDF
    
    Args:
        client: Ø¹Ù…ÙŠÙ„ Telethon
        message: Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    """
    links = set()
    
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… PyPDF2
        try:
            links.update(await _extract_from_pdf_pypdf2(client, message))
        except ImportError:
            logger.warning("PyPDF2 not installed")
        except Exception as e:
            logger.warning(f"PyPDF2 failed: {e}")
        
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø­ØµÙ„ Ø¹Ù„Ù‰ Ø±ÙˆØ§Ø¨Ø·ØŒ Ù†Ø¬Ø±Ø¨ pdfplumber
        if not links:
            try:
                links.update(await _extract_from_pdf_pdfplumber(client, message))
            except ImportError:
                logger.warning("pdfplumber not installed")
            except Exception as e:
                logger.warning(f"pdfplumber failed: {e}")
        
        # ÙÙ„ØªØ±Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        return _filter_links(list(links))
        
    except Exception as e:
        logger.error(f"PDF extraction error: {e}")
        return []

async def _extract_from_pdf_pypdf2(client: TelegramClient, message: Message) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† PDF Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… PyPDF2
    """
    links = set()
    
    try:
        from PyPDF2 import PdfReader
        
        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "document.pdf")
            await client.download_media(message, filepath)
            
            reader = PdfReader(filepath)
            
            for page_num, page in enumerate(reader.pages, 1):
                try:
                    text = page.extract_text() or ""
                    if text:
                        page_links = extract_links_from_text(text)
                        links.update(page_links)
                        
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† Ø§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª Ø§Ù„ØªÙˆØ¶ÙŠØ­ÙŠØ© (Annotations)
                        if hasattr(page, 'annotations') and page.annotations:
                            for annotation in page.annotations:
                                if hasattr(annotation, 'get') and annotation.get('/A'):
                                    uri = annotation['/A'].get('/URI')
                                    if uri:
                                        links.add(uri)
                except Exception as e:
                    logger.warning(f"Error extracting from PDF page {page_num}: {e}")
                    continue
        
        return list(links)
        
    except Exception as e:
        raise e

async def _extract_from_pdf_pdfplumber(client: TelegramClient, message: Message) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† PDF Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… pdfplumber
    """
    links = set()
    
    try:
        import pdfplumber
        
        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "document.pdf")
            await client.download_media(message, filepath)
            
            with pdfplumber.open(filepath) as pdf:
                for page_num, page in enumerate(pdf.pages, 1):
                    try:
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ
                        text = page.extract_text() or ""
                        if text:
                            page_links = extract_links_from_text(text)
                            links.update(page_links)
                        
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· (Hyperlinks)
                        if hasattr(page, 'hyperlinks'):
                            for link in page.hyperlinks:
                                if link and hasattr(link, 'uri'):
                                    links.add(link.uri)
                    except Exception as e:
                        logger.warning(f"Error extracting from PDF page {page_num} with pdfplumber: {e}")
                        continue
        
        return list(links)
        
    except Exception as e:
        raise e

# ======================
# DOCX Extraction
# ======================

async def _extract_from_docx(client: TelegramClient, message: Message) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ù…Ù„Ù DOCX
    
    Args:
        client: Ø¹Ù…ÙŠÙ„ Telethon
        message: Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    """
    links = set()
    
    try:
        from docx import Document
        
        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "document.docx")
            await client.download_media(message, filepath)
            
            doc = Document(filepath)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† Ø§Ù„ÙÙ‚Ø±Ø§Øª
            for para in doc.paragraphs:
                if para.text:
                    para_links = extract_links_from_text(para.text)
                    links.update(para_links)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† Ø§Ù„Ø¬Ø¯Ø§ÙˆÙ„
            for table in doc.tables:
                for row in table.rows:
                    for cell in row.cells:
                        if cell.text:
                            cell_links = extract_links_from_text(cell.text)
                            links.update(cell_links)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† Ø§Ù„Ø±Ø¤ÙˆØ³ ÙˆØ§Ù„ØªØ°ÙŠÙŠÙ„Ø§Øª
            for section in doc.sections:
                # Ø§Ù„Ø±Ø£Ø³
                header = section.header
                if header:
                    for para in header.paragraphs:
                        if para.text:
                            header_links = extract_links_from_text(para.text)
                            links.update(header_links)
                
                # Ø§Ù„ØªØ°ÙŠÙŠÙ„
                footer = section.footer
                if footer:
                    for para in footer.paragraphs:
                        if para.text:
                            footer_links = extract_links_from_text(para.text)
                            links.update(footer_links)
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªØ´Ø¹Ø¨ÙŠØ©
            try:
                # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø±ÙˆØ§Ø¨Ø·
                for element in doc.element.iter():
                    if element.tag.endswith('}hyperlink'):
                        # Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ù† Ø§Ù„Ø³Ù…Ø©
                        for attr in element.attrib:
                            if 'href' in attr.lower():
                                link_url = element.attrib[attr]
                                if link_url:
                                    links.add(link_url)
            except:
                pass
        
        return _filter_links(list(links))
        
    except ImportError:
        logger.warning("python-docx not installed")
        return []
    except Exception as e:
        logger.error(f"DOCX extraction error: {e}")
        return []

# ======================
# DOC Extraction (Old Word Format)
# ======================

async def _extract_from_doc(client: TelegramClient, message: Message) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ù…Ù„Ù DOC (Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù‚Ø¯ÙŠÙ…)
    
    Args:
        client: Ø¹Ù…ÙŠÙ„ Telethon
        message: Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    """
    try:
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­ÙˆÙŠÙ„ DOC Ø¥Ù„Ù‰ DOCX Ø£Ùˆ Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙƒÙ…Ù„Ù Ù†ØµÙŠ
        return await _extract_generic(client, message)
        
    except Exception as e:
        logger.error(f"DOC extraction error: {e}")
        return []

# ======================
# Text File Extraction
# ======================

async def _extract_from_txt(client: TelegramClient, message: Message) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ù…Ù„Ù Ù†ØµÙŠ
    
    Args:
        client: Ø¹Ù…ÙŠÙ„ Telethon
        message: Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    """
    links = set()
    
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "document.txt")
            await client.download_media(message, filepath)
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© ÙØªØ­ Ø§Ù„Ù…Ù„Ù Ø¨ØªØ´ÙÙŠØ±Ø§Øª Ù…Ø®ØªÙ„ÙØ©
            encodings = ['utf-8', 'utf-8-sig', 'latin-1', 'cp1256', 'windows-1256', 'ascii']
            
            for encoding in encodings:
                try:
                    with open(filepath, 'r', encoding=encoding, errors='ignore') as f:
                        content = f.read()
                        file_links = extract_links_from_text(content)
                        links.update(file_links)
                    break  # Ù†Ø¬Ø­ØŒ ØªÙˆÙ‚Ù Ø¹Ù† Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©
                except UnicodeDecodeError:
                    continue
                except Exception as e:
                    logger.warning(f"Failed to read with encoding {encoding}: {e}")
                    continue
        
        return _filter_links(list(links))
        
    except Exception as e:
        logger.error(f"TXT extraction error: {e}")
        return []

# ======================
# RTF Extraction
# ======================

async def _extract_from_rtf(client: TelegramClient, message: Message) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ù…Ù„Ù RTF
    
    Args:
        client: Ø¹Ù…ÙŠÙ„ Telethon
        message: Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    """
    links = set()
    
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "document.rtf")
            await client.download_media(message, filepath)
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø¯Ø§Ù… striprtf
            try:
                from striprtf.striprtf import rtf_to_text
                
                with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                    rtf_content = f.read()
                    text_content = rtf_to_text(rtf_content)
                    file_links = extract_links_from_text(text_content)
                    links.update(file_links)
                    
            except ImportError:
                logger.warning("striprtf not installed, trying basic extraction")
                
                # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨Ø³ÙŠØ· Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… regex
                with open(filepath, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                    
                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Øµ ÙÙŠ RTF (Ù†Ù…Ø· Ø¨Ø³ÙŠØ·)
                    import re
                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Øµ Ø¨ÙŠÙ† Ø§Ù„Ø£Ù‚ÙˆØ§Ø³
                    text_pattern = r'\\\'(..)|\\u-?\d+\?|([a-zA-Z0-9\s\.,!?\-\+\(\)\[\]\{\}]+)'
                    text_matches = re.findall(text_pattern, content)
                    
                    extracted_text = ' '.join([''.join(match) for match in text_matches])
                    file_links = extract_links_from_text(extracted_text)
                    links.update(file_links)
                    
                    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±Ø© ÙÙŠ RTF
                    url_pattern = r'\\field\{\\\*\\fldinst HYPERLINK "([^"]+)"\}'
                    url_matches = re.findall(url_pattern, content, re.IGNORECASE)
                    links.update(url_matches)
        
        return _filter_links(list(links))
        
    except Exception as e:
        logger.error(f"RTF extraction error: {e}")
        return []

# ======================
# ODT Extraction
# ======================

async def _extract_from_odt(client: TelegramClient, message: Message) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ù…Ù„Ù ODT
    
    Args:
        client: Ø¹Ù…ÙŠÙ„ Telethon
        message: Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    """
    links = set()
    
    try:
        import zipfile
        from xml.etree import ElementTree as ET
        
        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "document.odt")
            await client.download_media(message, filepath)
            
            with zipfile.ZipFile(filepath, 'r') as odt_file:
                # Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø³ØªÙ†Ø¯
                if 'content.xml' in odt_file.namelist():
                    content_xml = odt_file.read('content.xml')
                    
                    # ØªØ­Ù„ÙŠÙ„ XML
                    namespaces = {
                        'text': 'urn:oasis:names:tc:opendocument:xmlns:text:1.0',
                        'office': 'urn:oasis:names:tc:opendocument:xmlns:office:1.0',
                        'draw': 'urn:oasis:names:tc:opendocument:xmlns:drawing:1.0'
                    }
                    
                    try:
                        root = ET.fromstring(content_xml)
                        
                        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ø¬Ù…ÙŠØ¹ Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù†Øµ
                        for elem in root.findall('.//text:p', namespaces):
                            if elem.text:
                                elem_links = extract_links_from_text(elem.text)
                                links.update(elem_links)
                        
                        for elem in root.findall('.//text:span', namespaces):
                            if elem.text:
                                elem_links = extract_links_from_text(elem.text)
                                links.update(elem_links)
                        
                        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø·
                        for elem in root.findall('.//text:a', namespaces):
                            href = elem.get('{http://www.w3.org/1999/xlink}href')
                            if href:
                                links.add(href)
                                
                    except Exception as e:
                        logger.warning(f"Error parsing ODT XML: {e}")
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© ÙƒÙ…Ù„Ù Ù†ØµÙŠ Ø¨Ø³ÙŠØ·
                try:
                    # Ù‚Ø±Ø§Ø¡Ø© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù†ØµÙŠØ© ÙÙŠ Ø§Ù„Ø£Ø±Ø´ÙŠÙ
                    for file_info in odt_file.infolist():
                        if file_info.filename.endswith('.xml') or file_info.filename.endswith('.txt'):
                            try:
                                content = odt_file.read(file_info.filename).decode('utf-8', errors='ignore')
                                file_links = extract_links_from_text(content)
                                links.update(file_links)
                            except:
                                continue
                except:
                    pass
        
        return _filter_links(list(links))
        
    except ImportError:
        logger.warning("Could not process ODT file (missing libraries)")
        return []
    except Exception as e:
        logger.error(f"ODT extraction error: {e}")
        return []

# ======================
# Generic Text Extraction
# ======================

async def _extract_generic(client: TelegramClient, message: Message) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†Øµ Ø¹Ø§Ù… Ù…Ù† Ø£ÙŠ Ù…Ù„Ù
    
    Args:
        client: Ø¹Ù…ÙŠÙ„ Telethon
        message: Ø§Ù„Ø±Ø³Ø§Ù„Ø©
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    """
    links = set()
    
    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            filepath = os.path.join(tmpdir, "document")
            await client.download_media(message, filepath)
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù ÙƒÙ†Øµ Ø«Ù†Ø§Ø¦ÙŠ
            with open(filepath, 'rb') as f:
                content = f.read()
                
                # Ù…Ø­Ø§ÙˆÙ„Ø© ÙÙƒ Ø§Ù„ØªØ´ÙÙŠØ± ÙƒÙ†Øµ
                try:
                    text = content.decode('utf-8', errors='ignore')
                    file_links = extract_links_from_text(text)
                    links.update(file_links)
                except:
                    # Ø§Ù„Ø¨Ø­Ø« Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù† Ø£Ù†Ù…Ø§Ø· URLs ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ©
                    import re
                    # Ù†Ù…Ø· Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ URLs ÙÙŠ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ©
                    url_pattern = rb'https?://[^\x00-\x1F\x7F-\xFF<>"\s]+'
                    binary_matches = re.findall(url_pattern, content)
                    
                    for match in binary_matches:
                        try:
                            url = match.decode('utf-8', errors='ignore')
                            if url:
                                links.add(url)
                        except:
                            pass
        
        return _filter_links(list(links))
        
    except Exception as e:
        logger.error(f"Generic extraction error: {e}")
        return []

# ======================
# Link Filtering
# ======================

def _filter_links(links: List[str]) -> List[str]:
    """
    ÙÙ„ØªØ±Ø© ÙˆØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
    
    Args:
        links: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø®Ø§Ù…
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù†Ø¸ÙŠÙØ© ÙˆØ§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§
    """
    if not links:
        return []
    
    filtered_links = set()
    
    for link in links:
        try:
            # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø§Ø¨Ø·
            cleaned = clean_link(link)
            if not cleaned:
                continue
            
            # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø³Ù…ÙˆØ­Ø§Ù‹ Ø¨Ù‡
            if is_allowed_link(cleaned):
                filtered_links.add(cleaned)
                
        except Exception as e:
            logger.debug(f"Error filtering link {link}: {e}")
            continue
    
    return list(filtered_links)

# ======================
# Batch Processing
# ======================

async def extract_links_from_files_batch(
    client: TelegramClient,
    messages: List[Message],
    max_concurrent: int = 3
) -> Dict[str, List[str]]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª Ø¨Ø´ÙƒÙ„ Ù…ØªØ²Ø§Ù…Ù†
    
    Args:
        client: Ø¹Ù…ÙŠÙ„ Telethon
        messages: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
        max_concurrent: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ Ù†ÙØ³ Ø§Ù„ÙˆÙ‚Øª
        
    Returns:
        dict: Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù„ÙƒÙ„ Ù…Ù„Ù
    """
    results = {}
    
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def process_message(message: Message):
        async with semaphore:
            filename = message.file.name if message.file else "unknown"
            links = await extract_links_from_file(client, message)
            return filename, links
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ø§Ù… Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
    tasks = []
    for message in messages:
        if message and message.file:
            task = asyncio.create_task(process_message(message))
            tasks.append(task)
    
    # Ø§Ù†ØªØ¸Ø§Ø± Ø§ÙƒØªÙ…Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ù‡Ø§Ù…
    for task in asyncio.as_completed(tasks):
        try:
            filename, links = await task
            results[filename] = links
        except Exception as e:
            logger.error(f"Error processing file in batch: {e}")
    
    return results

# ======================
# Test Functions
# ======================

def test_file_support():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ø¹Ù… Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ù„ÙØ§Øª"""
    print("\n" + "="*50)
    print("ğŸ§ª Testing File Support")
    print("="*50)
    
    test_files = [
        ("document.pdf", "application/pdf"),
        ("report.docx", "application/vnd.openxmlformats-officedocument.wordprocessingml.document"),
        ("notes.txt", "text/plain"),
        ("file.rtf", "application/rtf"),
        ("document.odt", "application/vnd.oasis.opendocument.text"),
        ("script.exe", "application/x-msdownload"),
        ("archive.zip", "application/zip"),
    ]
    
    for filename, mime_type in test_files:
        supported = is_file_supported(filename, mime_type)
        status = "âœ… Ù…Ø¯Ø¹ÙˆÙ…" if supported else "âŒ ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…"
        file_type = get_file_type(filename, mime_type)
        print(f"{status} {filename} ({mime_type}) -> {file_type}")
    
    print("\nğŸ“Š Ø­Ø¬Ù… Ø§Ù„Ù…Ù„ÙØ§Øª:")
    test_sizes = [50, 100, 50000000, 60000000, 100000000]
    for size in test_sizes:
        valid = is_file_size_valid(size)
        status = "âœ… Ù…Ù‚Ø¨ÙˆÙ„" if valid else "âŒ Ù…Ø±ÙÙˆØ¶"
        print(f"{status} {size:,} Ø¨Ø§ÙŠØª")
    
    print("\n" + "="*50)

async def test_extraction():
    """Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬"""
    print("\nğŸ§ª Testing Extraction Functions")
    
    # Ù‡Ø°Ø§ Ø§Ø®ØªØ¨Ø§Ø± Ù†Ø¸Ø±ÙŠ Ø¨Ø¯ÙˆÙ† Ø¹Ù…ÙŠÙ„ Ø­Ù‚ÙŠÙ‚ÙŠ
    print("âœ… File extractors module is ready!")
    print("ğŸ“‹ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¯Ø¹ÙˆÙ…Ø©:")
    for ext, desc in SUPPORTED_EXTENSIONS.items():
        print(f"  â€¢ {ext} - {desc}")
    
    print("\nğŸ“¦ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©:")
    libraries = [
        ("PyPDF2", "Ù„Ù…Ù„ÙØ§Øª PDF"),
        ("python-docx", "Ù„Ù…Ù„ÙØ§Øª DOCX"),
        ("pdfplumber", "Ù„ØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ®Ø±Ø§Ø¬ PDF"),
        ("striprtf", "Ù„Ù…Ù„ÙØ§Øª RTF"),
    ]
    
    for lib_name, purpose in libraries:
        try:
            __import__(lib_name.replace('-', '_'))
            print(f"  âœ… {lib_name} - {purpose}")
        except ImportError:
            print(f"  âš ï¸  {lib_name} - {purpose} (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)")

# ======================
# Main Test
# ======================

if __name__ == "__main__":
    print("ğŸ”§ Testing File Extractors Module")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø¯Ø¹Ù… Ø§Ù„Ù…Ù„ÙØ§Øª
    test_file_support()
    
    # Ø§Ø®ØªØ¨Ø§Ø± ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬
    import asyncio
    asyncio.run(test_extraction())
    
    print("\n" + "="*50)
    print("âœ… File extractors module test completed successfully!")
    print("="*50)
