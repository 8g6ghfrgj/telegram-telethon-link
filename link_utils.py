import re
import logging
from typing import List, Dict, Optional, Tuple, Set
from urllib.parse import urlparse, parse_qs
import hashlib
from datetime import datetime

from config import (
    IGNORED_PATTERNS, BLACKLISTED_DOMAINS,
    TELEGRAM_PUBLIC_GROUP_PATTERNS, TELEGRAM_PRIVATE_GROUP_PATTERNS,
    WHATSAPP_LINK_PATTERNS
)

# ======================
# Logging
# ======================

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ======================
# URL Normalization
# ======================

def normalize_url(url: str) -> str:
    """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø±Ø§Ø¨Ø· (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù€ query parameters ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©)"""
    if not url or not isinstance(url, str):
        return ""
    
    url = url.strip()
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    url = re.sub(r'\s+', '', url)
    
    # Ø¥Ø¶Ø§ÙØ© https:// Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø§Ø¨Ø·
    parsed = urlparse(url)
    
    # ØªÙ†Ø¸ÙŠÙ query parameters
    query_params = parse_qs(parsed.query)
    
    # Ø¥Ø²Ø§Ù„Ø© parameters Ø§Ù„ØªØªØ¨Ø¹
    tracking_params = ['utm_', 'si=', 'ref=', 'share=', 'fbclid=', 'igshid=', 't=']
    clean_params = {}
    
    for key, values in query_params.items():
        if not any(key.startswith(param.rstrip('_')) for param in tracking_params):
            clean_params[key] = values
    
    # Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ query string Ù†Ø¸ÙŠÙ
    if clean_params:
        clean_query = '&'.join(
            f"{key}={value[0]}" if len(value) == 1 else f"{key}={','.join(value)}"
            for key, value in clean_params.items()
        )
    else:
        clean_query = ''
    
    # Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø§Ø¨Ø·
    clean_url = f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
    if clean_query:
        clean_url += f"?{clean_query}"
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù€ trailing slash
    if clean_url.endswith('/'):
        clean_url = clean_url[:-1]
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø­Ø±ÙˆÙ ØµØºÙŠØ±Ø© (Ù„Ù„ØªØ·Ø¨ÙŠØ¹)
    clean_url = clean_url.lower()
    
    return clean_url

def get_url_hash(url: str) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ hash Ù„Ù„Ø±Ø§Ø¨Ø· Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±"""
    normalized = normalize_url(url)
    return hashlib.md5(normalized.encode()).hexdigest()

# ======================
# URL Validation
# ======================

def is_valid_url(url: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø§Ø¨Ø· (Ø¨Ø¯ÙˆÙ† ØªØ·Ø¨ÙŠØ¹ Ø¯Ø§Ø®Ù„ÙŠ)"""
    if not url or not isinstance(url, str):
        return False
    
    url = url.strip()
    
    # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
    url_pattern = re.compile(
        r'^https?://'  # http:// or https://
        r'(([A-Za-z0-9]([A-Za-z0-9-]{0,61}[A-Za-z0-9])?\.)+[A-Za-z]{2,63}'  # domain
        r'|localhost)'  # or localhost
        r'(:\d+)?'  # optional port
        r'(/.*)?$'  # optional path
    )
    
    return bool(url_pattern.match(url))

def is_url_ignored(url: str) -> Tuple[bool, str]:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠØ¬Ø¨ ØªØ¬Ø§Ù‡Ù„Ù‡ Ù…Ø¹ Ø§Ù„Ø³Ø¨Ø¨"""
    if not url:
        return True, "Ø±Ø§Ø¨Ø· ÙØ§Ø±Øº"
    
    url_lower = url.lower()
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ù…Ù†ÙˆØ¹Ø©
    for pattern in IGNORED_PATTERNS:
        if re.search(pattern, url_lower, re.IGNORECASE):
            return True, f"ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ù…Ù…Ù†ÙˆØ¹: {pattern}"
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ù…Ù…Ù†ÙˆØ¹Ø©
    for domain in BLACKLISTED_DOMAINS:
        if domain.lower() in url_lower:
            return True, f"ÙŠØªØ¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ù…Ù†ÙˆØ¹: {domain}"
    
    # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù‚ØµÙŠØ±Ø© (Ù…Ø´Ø¨ÙˆÙ‡Ø©)
    if len(url) < 15:
        return True, "Ø±Ø§Ø¨Ø· Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ (Ù…Ø´Ø¨ÙˆÙ‡)"
    
    # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹ (Ù…Ø´Ø¨ÙˆÙ‡Ø©)
    if len(url) > 500:
        return True, "Ø±Ø§Ø¨Ø· Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹ (Ù…Ø´Ø¨ÙˆÙ‡)"
    
    return False, ""

# ======================
# Platform Detection
# ======================

def detect_platform(url: str) -> Optional[str]:
    """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†ØµØ© Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
    url_lower = url.lower()
    
    if any(pattern in url_lower for pattern in ['t.me', 'telegram.me', 'tg://']):
        return 'telegram'
    elif any(pattern in url_lower for pattern in ['whatsapp.com', 'wa.me', 'chat.whatsapp.com']):
        return 'whatsapp'
    
    return 'other'

def is_telegram_link(url: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø®Ø§Øµ Ø¨ØªÙ„ÙŠØ¬Ø±Ø§Ù…"""
    url_lower = url.lower()
    return any(pattern in url_lower for pattern in ['t.me', 'telegram.me', 'tg://'])

def is_whatsapp_link(url: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø®Ø§Øµ Ø¨ÙˆØ§ØªØ³Ø§Ø¨"""
    url_lower = url.lower()
    return any(pattern in url_lower for pattern in ['whatsapp.com', 'wa.me', 'chat.whatsapp.com'])

# ======================
# Telegram Link Analysis
# ======================

def extract_telegram_username(url: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø±Ø§Ø¨Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…"""
    patterns = [
        r't\.me/([A-Za-z0-9_]+)',
        r'telegram\.me/([A-Za-z0-9_]+)',
        r'tg://resolve\?domain=([A-Za-z0-9_]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            username = match.group(1)
            
            # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ query parameters
            if '?' in username:
                username = username.split('?')[0]
            if '/' in username:
                username = username.split('/')[0]
            
            username = username.lower()
            
            # ØªØµÙÙŠØ© Ø£Ø³Ù…Ø§Ø¡ ØºÙŠØ± ØµØ§Ù„Ø­Ø©
            if username == 'c':  # Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù‚Ù†ÙˆØ§Øª t.me/c/123456
                return None
            if len(username) < 2:  # Ø£Ø³Ù…Ø§Ø¡ Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
                return None
            
            return username
    
    return None

def extract_telegram_invite_hash(url: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ hash Ø§Ù„Ø¯Ø¹ÙˆØ© Ù…Ù† Ø±Ø§Ø¨Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ø§Ù„Ø®Ø§Øµ"""
    patterns = [
        r't\.me/\+([A-Za-z0-9_-]+)',
        r'telegram\.me/\+([A-Za-z0-9_-]+)',
        r'tg://join\?invite=([A-Za-z0-9_-]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            invite_hash = match.group(1)
            if len(invite_hash) >= 5:  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ hash ØµØ§Ù„Ø­
                return invite_hash
    
    return None

def extract_telegram_message_id(url: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ù† Ø±Ø§Ø¨Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…"""
    patterns = [
        r't\.me/[A-Za-z0-9_]+/([0-9]+)',
        r'telegram\.me/[A-Za-z0-9_]+/([0-9]+)',
        r'tg://resolve\?domain=[A-Za-z0-9_]+&post=([0-9]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            message_id = match.group(1)
            if message_id.isdigit():
                return message_id
    
    return None

def is_telegram_public_group_link(url: str) -> Tuple[bool, str]:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ø¹Ø§Ù…Ø© Ù…Ø¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
    # Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© = Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
    for pattern in TELEGRAM_PUBLIC_GROUP_PATTERNS:
        if re.match(pattern, url, re.IGNORECASE):
            return True, 'high'
    
    # Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ø¹Ø§Ù…Ø© = Ø«Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø©
    if re.match(r'^https?://t\.me/[A-Za-z0-9_]+$', url, re.IGNORECASE):
        username = extract_telegram_username(url)
        if username and len(username) >= 3:
            return True, 'medium'
    
    return False, ''

def is_telegram_private_group_link(url: str) -> Tuple[bool, str]:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ø®Ø§ØµØ© Ù…Ø¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
    # Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© = Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
    for pattern in TELEGRAM_PRIVATE_GROUP_PATTERNS:
        if re.match(pattern, url, re.IGNORECASE):
            return True, 'high'
    
    # Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø¯Ø¹ÙˆØ© = Ø«Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø©
    invite_hash = extract_telegram_invite_hash(url)
    if invite_hash and len(invite_hash) >= 10:
        return True, 'medium'
    
    return False, ''

def classify_telegram_link(url: str) -> Tuple[str, Dict, str]:
    """ØªØµÙ†ÙŠÙ Ø±Ø§Ø¨Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ ÙˆÙ…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
    details = {}
    
    # 1. ØªØ­Ù‚Ù‚ Ù…Ù† Ø·Ù„Ø¨ Ø§Ù„Ø§Ù†Ø¶Ù…Ø§Ù… Ø£ÙˆÙ„Ø§Ù‹ - Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
    invite_hash = extract_telegram_invite_hash(url)
    if invite_hash:
        details['invite_hash'] = invite_hash
        details['confidence'] = 'high'
        return 'join_request', details, 'high'
    
    # 2. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø®Ø§ØµØ© - Ø«Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø© Ø¥Ù„Ù‰ Ø¹Ø§Ù„ÙŠØ©
    is_private, confidence = is_telegram_private_group_link(url)
    if is_private:
        if invite_hash:
            details['invite_hash'] = invite_hash
        details['confidence'] = confidence
        return 'private_group', details, confidence
    
    # 3. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø© - Ø«Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø© Ø¥Ù„Ù‰ Ø¹Ø§Ù„ÙŠØ©
    is_public, confidence = is_telegram_public_group_link(url)
    if is_public:
        username = extract_telegram_username(url)
        if username:
            details['username'] = username
        details['confidence'] = confidence
        return 'public_group', details, confidence
    
    # 4. Ø£ÙŠ Ø­Ø§Ù„Ø© Ø£Ø®Ø±Ù‰ - Ø«Ù‚Ø© Ù…Ù†Ø®ÙØ¶Ø© Ø£Ùˆ ØºÙŠØ± Ù…Ø¹Ø±ÙˆÙØ©
    username = extract_telegram_username(url)
    if username:
        details['username'] = username
    
    message_id = extract_telegram_message_id(url)
    if message_id:
        details['message_id'] = message_id
    
    return 'unknown', details, 'low'

# ======================
# WhatsApp Link Analysis
# ======================

def extract_whatsapp_group_id(url: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§ØªØ³Ø§Ø¨"""
    patterns = [
        r'chat\.whatsapp\.com/([A-Za-z0-9_-]+)',
        r'whatsapp\.com/channel/([A-Za-z0-9_-]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            group_id = match.group(1)
            if len(group_id) >= 5:  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ ID ØµØ§Ù„Ø­
                return group_id
    
    return None

def extract_whatsapp_phone_number(url: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ Ù…Ù† Ø±Ø§Ø¨Ø· ÙˆØ§ØªØ³Ø§Ø¨"""
    pattern = r'wa\.me/([0-9]+)'
    match = re.search(pattern, url, re.IGNORECASE)
    
    if match:
        phone = match.group(1)
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ù‚Ù…
        phone = re.sub(r'[^0-9]', '', phone)
        if len(phone) >= 8:  # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ø±Ù‚Ù… ØµØ§Ù„Ø­
            return phone
    
    return None

def is_whatsapp_group_link(url: str) -> Tuple[bool, str]:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§ØªØ³Ø§Ø¨ Ù…Ø¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
    for pattern in WHATSAPP_LINK_PATTERNS:
        if re.match(pattern, url, re.IGNORECASE):
            # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ù„ÙŠØ³ Ø±Ø§Ø¨Ø· Ù‡Ø§ØªÙ
            if 'wa.me/' in url and re.match(r'https?://wa\.me/[0-9]+', url, re.IGNORECASE):
                return False, ''
            
            group_id = extract_whatsapp_group_id(url)
            if group_id:
                # Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹ ID ÙˆØ§Ø¶Ø­ = Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
                if len(group_id) >= 10:
                    return True, 'high'
                else:
                    return True, 'medium'
    
    return False, ''

def classify_whatsapp_link(url: str) -> Tuple[str, Dict, str]:
    """ØªØµÙ†ÙŠÙ Ø±Ø§Ø¨Ø· ÙˆØ§ØªØ³Ø§Ø¨ Ù…Ø¹ ØªÙØ§ØµÙŠÙ„ ÙˆÙ…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
    details = {}
    
    # 1. ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª - Ø«Ù‚Ø© Ù…ØªÙˆØ³Ø·Ø© Ø¥Ù„Ù‰ Ø¹Ø§Ù„ÙŠØ©
    is_group, confidence = is_whatsapp_group_link(url)
    if is_group:
        group_id = extract_whatsapp_group_id(url)
        if group_id:
            details['group_id'] = group_id
        details['confidence'] = confidence
        return 'group', details, confidence
    
    # 2. ØªØ­Ù‚Ù‚ Ù…Ù† Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù‡Ø§ØªÙ - Ø«Ù‚Ø© Ø¹Ø§Ù„ÙŠØ©
    phone_number = extract_whatsapp_phone_number(url)
    if phone_number:
        details['phone_number'] = phone_number
        return 'phone', details, 'high'
    
    return 'unknown', details, 'low'

# ======================
# General Link Analysis
# ======================

def analyze_link(url: str) -> Dict:
    """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ø±Ø§Ø¨Ø·"""
    result = {
        'url': url,
        'normalized_url': '',
        'url_hash': '',
        'is_valid': False,
        'platform': 'unknown',
        'link_type': 'unknown',
        'details': {},
        'can_verify': False,
        'confidence': 'low',
        'ignored': False,
        'ignore_reason': ''
        # Ù„Ø§ ÙŠÙˆØ¬Ø¯ 'reason' Ù‡Ù†Ø§ - ÙÙ‚Ø· Ù„Ù„ÙØ´Ù„
    }
    
    try:
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø±Ø§Ø¨Ø· (Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø© ÙÙ‚Ø·)
        normalized = normalize_url(url)
        result['normalized_url'] = normalized
        result['url_hash'] = hashlib.md5(normalized.encode()).hexdigest()
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø¨Ø¯ÙˆÙ† ØªØ·Ø¨ÙŠØ¹ Ø¯Ø§Ø®Ù„ÙŠ)
        if not is_valid_url(url):  # Ù†Ø³ØªØ®Ø¯Ù… url Ø§Ù„Ø£ØµÙ„ÙŠØ© Ù„Ù„ØªØ­Ù‚Ù‚
            result['is_valid'] = False
            return result
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ ØªØ¬Ø§Ù‡Ù„Ù‡
        ignored, ignore_reason = is_url_ignored(normalized)
        if ignored:
            result['is_valid'] = True  # ØµØ§Ù„Ø­ Ù„ÙƒÙ† Ù…Ù…Ù†ÙˆØ¹
            result['ignored'] = True
            result['ignore_reason'] = ignore_reason
            return result
        
        result['is_valid'] = True
        
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†ØµØ©
        platform = detect_platform(normalized)
        result['platform'] = platform
        
        # ØªØµÙ†ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ©
        if platform == 'telegram':
            link_type, details, confidence = classify_telegram_link(normalized)
            result['link_type'] = link_type
            result['details'] = details
            result['confidence'] = confidence
            
            # ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡
            if link_type in ['public_group', 'private_group', 'join_request']:
                result['can_verify'] = True
            else:
                result['can_verify'] = False
        
        elif platform == 'whatsapp':
            link_type, details, confidence = classify_whatsapp_link(normalized)
            result['link_type'] = link_type
            result['details'] = details
            result['confidence'] = confidence
            
            # ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠÙ…ÙƒÙ† Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù†Ù‡
            if link_type == 'group':
                result['can_verify'] = True
            else:
                result['can_verify'] = False
        
        else:
            # Ù…Ù†ØµØ§Øª Ø£Ø®Ø±Ù‰ ØºÙŠØ± Ù‚Ø§Ø¨Ù„Ø© Ù„Ù„ØªØ­Ù‚Ù‚
            result['can_verify'] = False
            result['confidence'] = 'low'
        
        return result
        
    except Exception as e:
        logger.error(f"Error analyzing link {url}: {e}")
        # Ø¹Ù†Ø¯ Ø§Ù„Ø®Ø·Ø£ØŒ Ù†Ø±Ø¬Ø¹ Ø§Ù„Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù…Ø¹ is_valid = False
        result['is_valid'] = False
        return result

def analyze_links_batch(urls: List[str]) -> Dict:
    """ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©"""
    results = {
        'total': len(urls),
        'valid': 0,
        'invalid': 0,
        'ignored': 0,
        'can_verify': 0,
        'by_platform': {},
        'by_type': {},
        'by_confidence': {'high': 0, 'medium': 0, 'low': 0},
        'details': []
    }
    
    for url in urls:
        analysis = analyze_link(url)
        results['details'].append(analysis)
        
        if not analysis['is_valid']:
            results['invalid'] += 1
        elif analysis['ignored']:
            results['ignored'] += 1
        else:
            results['valid'] += 1
            
            if analysis['can_verify']:
                results['can_verify'] += 1
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ù†ØµØ©
            platform = analysis['platform']
            if platform not in results['by_platform']:
                results['by_platform'][platform] = 0
            results['by_platform'][platform] += 1
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†ÙˆØ¹
            link_type = analysis['link_type']
            key = f"{platform}_{link_type}"
            if key not in results['by_type']:
                results['by_type'][key] = 0
            results['by_type'][key] += 1
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø«Ù‚Ø©
            confidence = analysis.get('confidence', 'low')
            if confidence in results['by_confidence']:
                results['by_confidence'][confidence] += 1
    
    return results

# ======================
# Link Filtering
# ======================

def filter_links_by_verifiability(urls: List[str], min_confidence: str = 'low') -> Tuple[List[Dict], Dict]:
    """ØªØµÙÙŠØ© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­Ø³Ø¨ Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆÙ…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©"""
    verifiable = []
    stats = {
        'total': len(urls),
        'verifiable': 0,
        'ignored': 0,
        'invalid': 0,
        'telegram': 0,
        'whatsapp': 0,
        'by_confidence': {'high': 0, 'medium': 0, 'low': 0},
        'ignored_reasons': {}
    }
    
    # ØªØ±ØªÙŠØ¨ Ù…Ø³ØªÙˆÙŠØ§Øª Ø§Ù„Ø«Ù‚Ø©
    confidence_levels = {'high': 3, 'medium': 2, 'low': 1}
    min_level = confidence_levels.get(min_confidence, 1)
    
    seen_hashes = set()
    
    for url in urls:
        analysis = analyze_link(url)
        
        if not analysis['is_valid']:
            stats['invalid'] += 1
            continue
        
        if analysis['ignored']:
            stats['ignored'] += 1
            reason = analysis.get('ignore_reason', 'unknown')
            if reason not in stats['ignored_reasons']:
                stats['ignored_reasons'][reason] = 0
            stats['ignored_reasons'][reason] += 1
            continue
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±
        url_hash = analysis['url_hash']
        if url_hash in seen_hashes:
            continue
        seen_hashes.add(url_hash)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ù‚Ø§Ø¨Ù„ÙŠØ© Ø§Ù„ØªØ­Ù‚Ù‚ ÙˆÙ…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø©
        if analysis['can_verify']:
            confidence = analysis.get('confidence', 'low')
            confidence_value = confidence_levels.get(confidence, 0)
            
            if confidence_value >= min_level:
                verifiable.append(analysis)
                stats['verifiable'] += 1
                
                # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø«Ù‚Ø©
                if confidence in stats['by_confidence']:
                    stats['by_confidence'][confidence] += 1
                
                if analysis['platform'] == 'telegram':
                    stats['telegram'] += 1
                elif analysis['platform'] == 'whatsapp':
                    stats['whatsapp'] += 1
    
    return verifiable, stats

# ======================
# URL Cleaning
# ======================

def clean_url_list(urls: List[str]) -> List[str]:
    """ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø·"""
    cleaned = []
    seen = set()
    
    for url in urls:
        if not url or not isinstance(url, str):
            continue
        
        normalized = normalize_url(url)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© (Ø¨Ø¯ÙˆÙ† ØªØ·Ø¨ÙŠØ¹ Ø¯Ø§Ø®Ù„ÙŠ)
        if not is_valid_url(url):
            continue
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±
        url_hash = hashlib.md5(normalized.encode()).hexdigest()
        if url_hash in seen:
            continue
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ¬Ø§Ù‡Ù„
        ignored, _ = is_url_ignored(normalized)
        if ignored:
            continue
        
        cleaned.append(normalized)
        seen.add(url_hash)
    
    return cleaned

def extract_urls_from_text(text: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„Ù†Øµ"""
    if not text:
        return []
    
    # Ù†Ù…Ø· Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    url_pattern = re.compile(
        r'https?://'  # http:// or https://
        r'(?:[A-Za-z0-9](?:[A-Za-z0-9-]{0,61}[A-Za-z0-9])?\.)+'  # domain
        r'[A-Za-z]{2,63}'  # TLD
        r'(?:[/\w .?=&%-]*)?',  # path and query
        re.IGNORECASE
    )
    
    urls = url_pattern.findall(text)
    return clean_url_list(urls)

# ======================
# Test Functions
# ======================

def test_link_analysis():
    """Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·"""
    test_urls = [
        "https://t.me/test_group",
        "https://t.me/+ABC123def",
        "https://t.me/c/123456",  # Ø±Ø§Ø¨Ø· Ù‚Ù†Ø§Ø©
        "https://chat.whatsapp.com/ABC123def",
        "https://wa.me/966501234567",
        "https://t.me/test_group/123",  # Ø±Ø§Ø¨Ø· Ø±Ø³Ø§Ù„Ø©
        "https://t.me/a",  # Ø±Ø§Ø¨Ø· Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹
        "https://t.me/very_long_username_test_here",  # Ø§Ø³Ù… Ø·ÙˆÙŠÙ„
        "https://t.me/+inv",  # invite Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹
        "https://facebook.com/groups/test"  # Ù…Ù†ØµØ© Ø£Ø®Ø±Ù‰
    ]
    
    print("ğŸ” Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·...")
    print("=" * 80)
    
    for url in test_urls:
        analysis = analyze_link(url)
        
        print(f"\nğŸ“Œ Ø§Ù„Ø±Ø§Ø¨Ø·: {url}")
        print(f"   ğŸ“± Ø§Ù„Ù…Ù†ØµØ©: {analysis['platform']}")
        print(f"   ğŸ·ï¸  Ø§Ù„Ù†ÙˆØ¹: {analysis['link_type']}")
        print(f"   âœ… ØµØ§Ù„Ø­: {analysis['is_valid']}")
        print(f"   ğŸ” Ù‚Ø§Ø¨Ù„ Ù„Ù„ØªØ­Ù‚Ù‚: {analysis['can_verify']}")
        print(f"   â­ Ø§Ù„Ø«Ù‚Ø©: {analysis.get('confidence', 'N/A')}")
        
        if analysis['ignored']:
            print(f"   â­ï¸  Ù…ØªØ¬Ø§Ù‡Ù„: {analysis.get('ignore_reason', 'N/A')}")
        
        if analysis['details']:
            print(f"   ğŸ” Ø§Ù„ØªÙØ§ØµÙŠÙ„: {analysis['details']}")
    
    print("\n" + "=" * 80)
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø¯ÙØ¹Ø© Ù…Ø¹ ØªØµÙÙŠØ©
    print("\nğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø·...")
    verifiable_links, stats = filter_links_by_verifiability(test_urls, 'medium')
    
    print(f"   ğŸ“ˆ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {stats['total']}")
    print(f"   âœ… ØµØ§Ù„Ø­Ø© Ù„Ù„ØªØ­Ù‚Ù‚: {stats['verifiable']}")
    print(f"   âŒ ØºÙŠØ± ØµØ§Ù„Ø­Ø©: {stats['invalid']}")
    print(f"   â­ï¸  Ù…ØªØ¬Ø§Ù‡Ù„Ø©: {stats['ignored']}")
    
    print(f"\n   ğŸ“± Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ©:")
    print(f"      â€¢ ØªÙ„ÙŠØ¬Ø±Ø§Ù…: {stats['telegram']}")
    print(f"      â€¢ ÙˆØ§ØªØ³Ø§Ø¨: {stats['whatsapp']}")
    
    print(f"\n   â­ Ø­Ø³Ø¨ Ø§Ù„Ø«Ù‚Ø©:")
    for conf_level, count in stats['by_confidence'].items():
        if count > 0:
            print(f"      â€¢ {conf_level}: {count}")
    
    # Ø§Ø®ØªØ¨Ø§Ø± link_utils Ù…Ø¹ bot.py
    print("\n" + "=" * 80)
    print("ğŸ¯ ÙƒÙŠÙ ÙŠØ³ØªØ®Ø¯Ù…Ù‡Ø§ bot.py:")
    print("=" * 80)
    
    example_url = "https://t.me/test_group"
    analysis = analyze_link(example_url)
    
    print(f"\nØ§Ù„Ø±Ø§Ø¨Ø·: {example_url}")
    print(f"ÙŠÙ…ÙƒÙ† Ù„Ù€ bot.py Ø£Ù†:")
    
    if analysis['can_verify']:
        print(f"1. Ø§Ø³ØªØ®Ø¯Ø§Ù… can_verify = {analysis['can_verify']} Ù„Ù„Ù…ØªØ§Ø¨Ø¹Ø©")
        print(f"2. Ø§Ø³ØªØ®Ø¯Ø§Ù… confidence = {analysis['confidence']} Ù„ØªØ±ØªÙŠØ¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ§Øª")
        print(f"3. ØªÙ…Ø±ÙŠØ± details Ø¥Ù„Ù‰ Telethon Ù„Ù„ØªØ­Ù‚Ù‚: {analysis['details']}")
        print(f"4. Ø§Ù„Ù‚Ø±Ø§Ø± Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ ÙÙŠ bot.py Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ù†ØªÙŠØ¬Ø© Telethon")
    else:
        print(f"1. ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø±Ø§Ø¨Ø· (can_verify = False)")
        print(f"2. Ø§Ù„Ø«Ù‚Ø©: {analysis.get('confidence', 'N/A')}")
        if analysis['ignored']:
            print(f"3. Ø§Ù„Ø³Ø¨Ø¨: {analysis.get('ignore_reason', 'N/A')}")

# ======================
# Main Entry Point
# ======================

if __name__ == "__main__":
    print("ğŸ”§ ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± link_utils.py...")
    print("âš¡ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù ÙŠÙˆÙØ± Ø£Ø¯ÙˆØ§Øª ØªØ­Ù„ÙŠÙ„ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    print("\n" + "=" * 80)
    test_link_analysis()
    
    print("\nâœ… Ø§Ø®ØªØ¨Ø§Ø± link_utils.py Ø§ÙƒØªÙ…Ù„ Ø¨Ù†Ø¬Ø§Ø­!")
