import re
import logging
from typing import List, Dict, Optional, Tuple, Set
from urllib.parse import urlparse, parse_qs
import hashlib

from config import (
    IGNORED_PATTERNS, BLACKLISTED_DOMAINS,
    TELEGRAM_PUBLIC_GROUP_PATTERNS, TELEGRAM_PRIVATE_GROUP_PATTERNS,
    TELEGRAM_CHANNEL_PATTERNS, WHATSAPP_LINK_PATTERNS,
    FILTER_CHANNELS, FILTER_EMPTY_GROUPS, FILTER_BANNED_GROUPS,
    FILTER_DEAD_LINKS
)

# ======================
# Logging
# ======================

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ======================
# Constants
# ======================

# Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹Ø±ÙˆÙØ© Ù„Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø´Ù‡ÙŠØ±Ø© (Ù„Ù„ØªØ¬Ø§Ù‡Ù„)
KNOWN_CHANNELS = {
    # Ù‚Ù†ÙˆØ§Øª Ø¥Ø®Ø¨Ø§Ø±ÙŠØ©
    'telegram', 'telegramtips', 'telegramchannels',
    'telegramstore', 'telegramandroid', 'telegramios',
    
    # Ù‚Ù†ÙˆØ§Øª Ø¹Ø±Ø¨ÙŠØ©
    'alarabiya', 'aljazeera', 'bbcnewsarabic',
    'skynewsarabia', 'cnnarabic', 'france24ar',
    
    # Ù‚Ù†ÙˆØ§Øª ØªÙ‚Ù†ÙŠØ©
    'tech', 'technology', 'android', 'ios', 'windows',
    
    # Ù‚Ù†ÙˆØ§Øª ØªØ±ÙÙŠÙ‡ÙŠØ©
    'movies', 'series', 'music', 'entertainment',
    
    # Ù‚Ù†ÙˆØ§Øª Ø±ÙŠØ§Ø¶ÙŠØ©
    'sports', 'football', 'soccer', 'basketball'
}

# ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ù†ÙˆØ§Øª
CHANNEL_KEYWORDS = [
    'Ù‚Ù†Ø§Ø©', 'ÙƒØ§Ù†Ø§Ù„', 'channel', 'news', 'Ø§Ø®Ø¨Ø§Ø±',
    'Ø¨Ø«', 'broadcast', 'Ø±Ø³Ù…ÙŠ', 'official',
    'Ø§Ø¹Ù„Ø§Ù†Ø§Øª', 'announcements', 'Ø§Ø®Ø¨Ø§Ø±ÙŠ', 'Ù†Ø´Ø±Ø§Øª'
]

# ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
GROUP_KEYWORDS = [
    'Ù…Ø¬Ù…ÙˆØ¹Ø©', 'Ø¬Ø±ÙˆØ¨', 'group', 'Ø´Ø§Øª', 'chat',
    'Ø¯Ø±Ø¯Ø´Ø©', 'ØªØ­Ø¯Ø«', 'talk', 'Ù†Ù‚Ø§Ø´', 'discussion',
    'Ø­ÙˆØ§Ø±', 'Ø§Ø¬ØªÙ…Ø§Ø¹', 'meeting', 'Ù…Ø¬ØªÙ…Ø¹', 'community'
]

# ======================
# URL Normalization
# ======================

def normalize_url(url: str) -> str:
    """ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø±Ø§Ø¨Ø· (Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù€ query parameters ØºÙŠØ± Ø§Ù„Ø¶Ø±ÙˆØ±ÙŠØ©)"""
    if not url or not isinstance(url, str):
        return ""
    
    url = url.strip()
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª Ø§Ù„Ø²Ø§Ø¦Ø¯Ø©
    url = re.sub(r'\s+', '', url)
    
    # Ø¥Ø¶Ø§ÙØ© https:// Ø¥Ø°Ø§ Ù„Ù… ÙŠÙƒÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹
    if not url.startswith(('http://', 'https://')):
        url = 'https://' + url
    
    # ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±Ø§Ø¨Ø·
    parsed = urlparse(url)
    
    # ØªÙ†Ø¸ÙŠÙ query parameters
    query_params = parse_qs(parsed.query)
    
    # Ø¥Ø²Ø§Ù„Ø© parameters Ø§Ù„ØªØªØ¨Ø¹
    tracking_params = ['utm_', 'si=', 'ref=', 'share=', 'fbclid=', 'igshid=', 't=']
    clean_params = {}
    
    for key, values in query_params.items():
        if not any(key.startswith(param.rstrip('_')) for param in tracking_params):
            clean_params[key] = values
    
    # Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ query string Ù†Ø¸ÙŠÙ
    if clean_params:
        clean_query = '&'.join(
            f"{key}={value[0]}" if len(value) == 1 else f"{key}={','.join(value)}"
            for key, value in clean_params.items()
        )
    else:
        clean_query = ''
    
    # Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø±Ø§Ø¨Ø·
    clean_url = f"{parsed.scheme}://{parsed.netloc}{parsed.path}"
    if clean_query:
        clean_url += f"?{clean_query}"
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù€ trailing slash
    if clean_url.endswith('/'):
        clean_url = clean_url[:-1]
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø­Ø±ÙˆÙ ØµØºÙŠØ±Ø© (Ù„Ù„ØªØ·Ø¨ÙŠØ¹)
    clean_url = clean_url.lower()
    
    return clean_url

def get_url_hash(url: str) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ hash Ù„Ù„Ø±Ø§Ø¨Ø· Ù„Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±"""
    normalized = normalize_url(url)
    return hashlib.md5(normalized.encode()).hexdigest()

# ======================
# URL Validation
# ======================

def is_valid_url(url: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø§Ø¨Ø·"""
    if not url or not isinstance(url, str):
        return False
    
    # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø±Ø§Ø¨Ø· Ø£ÙˆÙ„Ø§Ù‹
    url = normalize_url(url)
    
    # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
    url_pattern = re.compile(
        r'^(https?://)?'  # http:// or https://
        r'(([A-Za-z0-9]([A-Za-z0-9-]{0,61}[A-Za-z0-9])?\.)+[A-Za-z]{2,6}'  # domain
        r'|localhost)'  # or localhost
        r'(:\d+)?'  # optional port
        r'(/.*)?$'  # optional path
    )
    
    return bool(url_pattern.match(url))

def is_url_ignored(url: str) -> Tuple[bool, str]:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠØ¬Ø¨ ØªØ¬Ø§Ù‡Ù„Ù‡ Ù…Ø¹ Ø§Ù„Ø³Ø¨Ø¨"""
    if not url:
        return True, "Ø±Ø§Ø¨Ø· ÙØ§Ø±Øº"
    
    url_lower = url.lower()
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ù…Ù†ÙˆØ¹Ø©
    for pattern in IGNORED_PATTERNS:
        if re.search(pattern, url_lower, re.IGNORECASE):
            return True, f"ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ù…Ù…Ù†ÙˆØ¹: {pattern}"
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª Ø§Ù„Ù…Ù…Ù†ÙˆØ¹Ø©
    for domain in BLACKLISTED_DOMAINS:
        if domain.lower() in url_lower:
            return True, f"ÙŠØªØ¶Ù…Ù† Ø§Ù„Ù†Ø·Ø§Ù‚ Ø§Ù„Ù…Ù…Ù†ÙˆØ¹: {domain}"
    
    # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù‚ØµÙŠØ±Ø© (Ù…Ø´Ø¨ÙˆÙ‡Ø©)
    if len(url) < 15:
        return True, "Ø±Ø§Ø¨Ø· Ù‚ØµÙŠØ± Ø¬Ø¯Ø§Ù‹ (Ù…Ø´Ø¨ÙˆÙ‡)"
    
    # ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø¬Ø¯Ø§Ù‹ (Ù…Ø´Ø¨ÙˆÙ‡Ø©)
    if len(url) > 500:
        return True, "Ø±Ø§Ø¨Ø· Ø·ÙˆÙŠÙ„ Ø¬Ø¯Ø§Ù‹ (Ù…Ø´Ø¨ÙˆÙ‡)"
    
    return False, ""

# ======================
# Platform Detection
# ======================

def detect_platform(url: str) -> Optional[str]:
    """Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†ØµØ© Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
    url_lower = url.lower()
    
    if any(pattern in url_lower for pattern in ['t.me', 'telegram.me', 'tg://']):
        return 'telegram'
    elif any(pattern in url_lower for pattern in ['whatsapp.com', 'wa.me', 'chat.whatsapp.com']):
        return 'whatsapp'
    elif any(pattern in url_lower for pattern in ['facebook.com', 'fb.com', 'fb.me']):
        return 'facebook'
    elif any(pattern in url_lower for pattern in ['instagram.com', 'instagr.am']):
        return 'instagram'
    elif any(pattern in url_lower for pattern in ['twitter.com', 'x.com']):
        return 'twitter'
    elif any(pattern in url_lower for pattern in ['youtube.com', 'youtu.be']):
        return 'youtube'
    elif any(pattern in url_lower for pattern in ['linkedin.com']):
        return 'linkedin'
    elif any(pattern in url_lower for pattern in ['discord.com', 'discord.gg']):
        return 'discord'
    elif any(pattern in url_lower for pattern in ['signal.org', 'signal.me']):
        return 'signal'
    
    return 'other'

def is_telegram_link(url: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø®Ø§Øµ Ø¨ØªÙ„ÙŠØ¬Ø±Ø§Ù…"""
    url_lower = url.lower()
    return any(pattern in url_lower for pattern in ['t.me', 'telegram.me', 'tg://'])

def is_whatsapp_link(url: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø®Ø§Øµ Ø¨ÙˆØ§ØªØ³Ø§Ø¨"""
    url_lower = url.lower()
    return any(pattern in url_lower for pattern in ['whatsapp.com', 'wa.me', 'chat.whatsapp.com'])

# ======================
# Telegram Link Analysis
# ======================

def extract_telegram_username(url: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù…Ù† Ø±Ø§Ø¨Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…"""
    patterns = [
        r't\.me/([A-Za-z0-9_]+)',
        r'telegram\.me/([A-Za-z0-9_]+)',
        r'tg://resolve\?domain=([A-Za-z0-9_]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            username = match.group(1)
            # Ø¥Ø²Ø§Ù„Ø© Ø£ÙŠ query parameters
            if '?' in username:
                username = username.split('?')[0]
            if '/' in username:
                username = username.split('/')[0]
            return username.lower()
    
    return None

def extract_telegram_invite_hash(url: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ hash Ø§Ù„Ø¯Ø¹ÙˆØ© Ù…Ù† Ø±Ø§Ø¨Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ø§Ù„Ø®Ø§Øµ"""
    patterns = [
        r't\.me/\+([A-Za-z0-9_-]+)',
        r'telegram\.me/\+([A-Za-z0-9_-]+)',
        r'tg://join\?invite=([A-Za-z0-9_-]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            return match.group(1)
    
    return None

def extract_telegram_channel_id(url: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ù‚Ù†Ø§Ø© Ù…Ù† Ø±Ø§Ø¨Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…"""
    patterns = [
        r't\.me/c/([0-9]+)',
        r'telegram\.me/c/([0-9]+)',
        r'tg://privatepost\?channel=([0-9]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            return match.group(1)
    
    return None

def extract_telegram_message_id(url: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ù† Ø±Ø§Ø¨Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…"""
    patterns = [
        r't\.me/[A-Za-z0-9_]+/([0-9]+)',
        r'telegram\.me/[A-Za-z0-9_]+/([0-9]+)',
        r'tg://resolve\?domain=[A-Za-z0-9_]+&post=([0-9]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            return match.group(1)
    
    return None

def is_telegram_channel_link(url: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù‚Ù†Ø§Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…"""
    # Ø§Ù„Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù„Ù‚Ù†ÙˆØ§Øª
    for pattern in TELEGRAM_CHANNEL_PATTERNS:
        if re.match(pattern, url, re.IGNORECASE):
            return True
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
    username = extract_telegram_username(url)
    if username:
        # ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙŠØ´ÙŠØ± Ø¥Ù„Ù‰ Ù‚Ù†Ø§Ø©
        username_lower = username.lower()
        
        # ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ù†ÙˆØ§Øª
        for keyword in CHANNEL_KEYWORDS:
            if keyword in username_lower:
                return True
        
        # Ù‚Ù†ÙˆØ§Øª Ù…Ø¹Ø±ÙˆÙØ©
        if username_lower in KNOWN_CHANNELS:
            return True
        
        # Ù†Ù…Ø· Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù‚Ù†ÙˆØ§Øª (Ù…Ø«Ù„ ending with _channel)
        if username_lower.endswith(('_channel', 'channel', '_news', 'news')):
            return True
    
    return False

def is_telegram_group_link(url: str) -> Tuple[bool, str]:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ù…Ø¹ Ø§Ù„Ù†ÙˆØ¹"""
    # Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¹Ø§Ù…Ø©
    for pattern in TELEGRAM_PUBLIC_GROUP_PATTERNS:
        if re.match(pattern, url, re.IGNORECASE):
            # ØªØ­Ù‚Ù‚ Ù…Ù† Ø£Ù†Ù‡ Ù„ÙŠØ³ Ù‚Ù†Ø§Ø©
            if is_telegram_channel_link(url):
                return False, "channel"
            return True, "public_group"
    
    # Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø®Ø§ØµØ©
    for pattern in TELEGRAM_PRIVATE_GROUP_PATTERNS:
        if re.match(pattern, url, re.IGNORECASE):
            return True, "private_group"
    
    return False, "not_group"

def classify_telegram_link(url: str) -> Tuple[str, Dict]:
    """ØªØµÙ†ÙŠÙ Ø±Ø§Ø¨Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ù…Ø¹ ØªÙØ§ØµÙŠÙ„"""
    details = {}
    
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª
    username = extract_telegram_username(url)
    invite_hash = extract_telegram_invite_hash(url)
    channel_id = extract_telegram_channel_id(url)
    message_id = extract_telegram_message_id(url)
    
    if channel_id:
        details['channel_id'] = channel_id
        return 'channel', details
    
    if invite_hash:
        details['invite_hash'] = invite_hash
        
        # Ù…Ø­Ø§ÙˆÙ„Ø© ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø¬Ù…ÙˆØ¹Ø© Ø£Ùˆ Ù‚Ù†Ø§Ø©
        if FILTER_CHANNELS:
            # Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¹Ø§Ø¯Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ ÙƒÙ„Ù…Ø§Øª Ù…Ø¹ÙŠÙ†Ø©
            if any(keyword in url.lower() for keyword in GROUP_KEYWORDS):
                return 'private_group', details
            else:
                return 'channel', details
        else:
            return 'private_group', details
    
    if username:
        details['username'] = username
        
        # ØªØ­Ù„ÙŠÙ„ Ø§Ø³Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
        username_lower = username.lower()
        
        # ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ø¨ÙˆØªØ§Øª
        if username_lower.endswith('bot') or '_bot' in username_lower:
            return 'bot', details
        
        # ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª
        if any(keyword in username_lower for keyword in GROUP_KEYWORDS):
            return 'public_group', details
        
        # ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ù‚Ù†ÙˆØ§Øª
        if any(keyword in username_lower for keyword in CHANNEL_KEYWORDS):
            if FILTER_CHANNELS:
                return 'channel', details
            else:
                return 'public_group', details
        
        # Ù‚Ù†ÙˆØ§Øª Ù…Ø¹Ø±ÙˆÙØ©
        if username_lower in KNOWN_CHANNELS:
            if FILTER_CHANNELS:
                return 'channel', details
            else:
                return 'public_group', details
        
        # Ù†Ù…Ø· Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù‚Ù†ÙˆØ§Øª
        if (username_lower.endswith(('_channel', 'channel', '_news', 'news')) or
            username_lower.startswith(('channel_', 'news_'))):
            if FILTER_CHANNELS:
                return 'channel', details
            else:
                return 'public_group', details
        
        # Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠ: Ù…Ø¬Ù…ÙˆØ¹Ø© Ø¹Ø§Ù…Ø©
        return 'public_group', details
    
    if message_id:
        details['message_id'] = message_id
        return 'message', details
    
    return 'unknown', details

# ======================
# WhatsApp Link Analysis
# ======================

def extract_whatsapp_group_id(url: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ø±Ù Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§ØªØ³Ø§Ø¨"""
    patterns = [
        r'chat\.whatsapp\.com/([A-Za-z0-9_-]+)',
        r'whatsapp\.com/channel/([A-Za-z0-9_-]+)'
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url, re.IGNORECASE)
        if match:
            return match.group(1)
    
    return None

def extract_whatsapp_phone_number(url: str) -> Optional[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ù‚Ù… Ø§Ù„Ù‡Ø§ØªÙ Ù…Ù† Ø±Ø§Ø¨Ø· ÙˆØ§ØªØ³Ø§Ø¨"""
    pattern = r'wa\.me/([0-9]+)'
    match = re.search(pattern, url, re.IGNORECASE)
    
    if match:
        phone = match.group(1)
        # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ù‚Ù…
        phone = re.sub(r'[^0-9]', '', phone)
        return phone
    
    return None

def is_whatsapp_group_link(url: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§ØªØ³Ø§Ø¨"""
    for pattern in WHATSAPP_LINK_PATTERNS:
        if re.match(pattern, url, re.IGNORECASE):
            # ØªØ£ÙƒØ¯ Ø£Ù†Ù‡ Ù„ÙŠØ³ Ø±Ø§Ø¨Ø· Ù‡Ø§ØªÙ
            if 'wa.me/' in url and re.match(r'https?://wa\.me/[0-9]+', url, re.IGNORECASE):
                return False
            return True
    
    return False

def is_whatsapp_phone_link(url: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ø±Ù‚Ù… ÙˆØ§ØªØ³Ø§Ø¨"""
    pattern = r'https?://wa\.me/[0-9]+'
    return bool(re.match(pattern, url, re.IGNORECASE))

def classify_whatsapp_link(url: str) -> Tuple[str, Dict]:
    """ØªØµÙ†ÙŠÙ Ø±Ø§Ø¨Ø· ÙˆØ§ØªØ³Ø§Ø¨ Ù…Ø¹ ØªÙØ§ØµÙŠÙ„"""
    details = {}
    
    group_id = extract_whatsapp_group_id(url)
    phone_number = extract_whatsapp_phone_number(url)
    
    if group_id:
        details['group_id'] = group_id
        return 'group', details
    
    if phone_number:
        details['phone_number'] = phone_number
        return 'phone', details
    
    return 'unknown', details

# ======================
# General Link Analysis
# ======================

def analyze_link(url: str) -> Dict:
    """ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ Ù„Ù„Ø±Ø§Ø¨Ø·"""
    result = {
        'url': url,
        'normalized_url': '',
        'url_hash': '',
        'is_valid': False,
        'platform': 'unknown',
        'link_type': 'unknown',
        'details': {},
        'should_collect': False,
        'reason': '',
        'ignored': False,
        'ignore_reason': ''
    }
    
    try:
        # ØªØ·Ø¨ÙŠØ¹ Ø§Ù„Ø±Ø§Ø¨Ø·
        normalized = normalize_url(url)
        result['normalized_url'] = normalized
        result['url_hash'] = get_url_hash(url)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        if not is_valid_url(normalized):
            result['reason'] = 'ØªÙ†Ø³ÙŠÙ‚ Ø±Ø§Ø¨Ø· ØºÙŠØ± ØµØ§Ù„Ø­'
            return result
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ ØªØ¬Ø§Ù‡Ù„Ù‡
        ignored, ignore_reason = is_url_ignored(normalized)
        if ignored:
            result['ignored'] = True
            result['ignore_reason'] = ignore_reason
            result['reason'] = f'ØªÙ… ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø±Ø§Ø¨Ø·: {ignore_reason}'
            return result
        
        result['is_valid'] = True
        
        # Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù…Ù†ØµØ©
        platform = detect_platform(normalized)
        result['platform'] = platform
        
        # ØªØµÙ†ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ©
        if platform == 'telegram':
            link_type, details = classify_telegram_link(normalized)
            result['link_type'] = link_type
            result['details'] = details
            
            # ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ Ø¬Ù…Ø¹Ù‡
            if link_type in ['public_group', 'private_group']:
                result['should_collect'] = True
                result['reason'] = f'Ù…Ø¬Ù…ÙˆØ¹Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… ({link_type})'
            elif link_type == 'channel' and FILTER_CHANNELS:
                result['should_collect'] = False
                result['reason'] = 'Ù‚Ù†Ø§Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… (Ù…Ù‡Ù…Ù„Ø©)'
            else:
                result['should_collect'] = False
                result['reason'] = f'Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø· ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… ØºÙŠØ± Ù…Ø¬Ù…Ø¹: {link_type}'
        
        elif platform == 'whatsapp':
            link_type, details = classify_whatsapp_link(normalized)
            result['link_type'] = link_type
            result['details'] = details
            
            # ØªØ­Ø¯ÙŠØ¯ Ø¥Ø°Ø§ ÙƒØ§Ù† ÙŠØ¬Ø¨ Ø¬Ù…Ø¹Ù‡
            if link_type == 'group':
                result['should_collect'] = True
                result['reason'] = 'Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§ØªØ³Ø§Ø¨'
            else:
                result['should_collect'] = False
                result['reason'] = f'Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø· ÙˆØ§ØªØ³Ø§Ø¨ ØºÙŠØ± Ù…Ø¬Ù…Ø¹: {link_type}'
        
        else:
            result['reason'] = f'Ù…Ù†ØµØ© ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ…Ø©: {platform}'
        
        return result
        
    except Exception as e:
        logger.error(f"Error analyzing link {url}: {e}")
        result['reason'] = f'Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„: {str(e)}'
        return result

def analyze_links_batch(urls: List[str]) -> Dict:
    """ØªØ­Ù„ÙŠÙ„ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¯ÙØ¹Ø© ÙˆØ§Ø­Ø¯Ø©"""
    results = {
        'total': len(urls),
        'valid': 0,
        'invalid': 0,
        'ignored': 0,
        'to_collect': 0,
        'by_platform': {},
        'by_type': {},
        'details': []
    }
    
    for url in urls:
        analysis = analyze_link(url)
        results['details'].append(analysis)
        
        if not analysis['is_valid']:
            results['invalid'] += 1
        elif analysis['ignored']:
            results['ignored'] += 1
        else:
            results['valid'] += 1
            
            if analysis['should_collect']:
                results['to_collect'] += 1
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ù†ØµØ©
            platform = analysis['platform']
            if platform not in results['by_platform']:
                results['by_platform'][platform] = 0
            results['by_platform'][platform] += 1
            
            # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù†ÙˆØ¹
            link_type = analysis['link_type']
            key = f"{platform}_{link_type}"
            if key not in results['by_type']:
                results['by_type'][key] = 0
            results['by_type'][key] += 1
    
    return results

# ======================
# Link Filtering
# ======================

def filter_links_for_collection(urls: List[str]) -> Tuple[List[str], Dict]:
    """ØªØµÙÙŠØ© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù„Ù„Ø¬Ù…Ø¹ Ù…Ø¹ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª"""
    to_collect = []
    stats = {
        'total': len(urls),
        'collected': 0,
        'ignored': 0,
        'invalid': 0,
        'telegram_groups': 0,
        'whatsapp_groups': 0,
        'channels_skipped': 0,
        'ignored_reasons': {}
    }
    
    seen_hashes = set()
    
    for url in urls:
        analysis = analyze_link(url)
        
        if not analysis['is_valid']:
            stats['invalid'] += 1
            continue
        
        if analysis['ignored']:
            stats['ignored'] += 1
            reason = analysis.get('ignore_reason', 'unknown')
            if reason not in stats['ignored_reasons']:
                stats['ignored_reasons'][reason] = 0
            stats['ignored_reasons'][reason] += 1
            continue
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±
        url_hash = analysis['url_hash']
        if url_hash in seen_hashes:
            continue
        seen_hashes.add(url_hash)
        
        if analysis['should_collect']:
            to_collect.append(analysis['normalized_url'])
            stats['collected'] += 1
            
            if analysis['platform'] == 'telegram' and analysis['link_type'] in ['public_group', 'private_group']:
                stats['telegram_groups'] += 1
            elif analysis['platform'] == 'whatsapp' and analysis['link_type'] == 'group':
                stats['whatsapp_groups'] += 1
        
        elif analysis['platform'] == 'telegram' and analysis['link_type'] == 'channel':
            stats['channels_skipped'] += 1
    
    return to_collect, stats

# ======================
# URL Generation
# ======================

def generate_telegram_public_group_url(username: str) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ø¹Ø§Ù…Ø©"""
    username = re.sub(r'[^A-Za-z0-9_]', '', username)
    return f"https://t.me/{username}"

def generate_telegram_private_group_url(invite_hash: str) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù… Ø®Ø§ØµØ©"""
    invite_hash = re.sub(r'[^A-Za-z0-9_-]', '', invite_hash)
    return f"https://t.me/+{invite_hash}"

def generate_whatsapp_group_url(group_id: str) -> str:
    """Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø§Ø¨Ø· Ù…Ø¬Ù…ÙˆØ¹Ø© ÙˆØ§ØªØ³Ø§Ø¨"""
    group_id = re.sub(r'[^A-Za-z0-9_-]', '', group_id)
    return f"https://chat.whatsapp.com/{group_id}"

# ======================
# URL Cleaning
# ======================

def clean_url_list(urls: List[str]) -> List[str]:
    """ØªÙ†Ø¸ÙŠÙ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø·"""
    cleaned = []
    seen = set()
    
    for url in urls:
        if not url or not isinstance(url, str):
            continue
        
        normalized = normalize_url(url)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        if not is_valid_url(normalized):
            continue
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªÙƒØ±Ø§Ø±
        url_hash = get_url_hash(normalized)
        if url_hash in seen:
            continue
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ¬Ø§Ù‡Ù„
        ignored, _ = is_url_ignored(normalized)
        if ignored:
            continue
        
        cleaned.append(normalized)
        seen.add(url_hash)
    
    return cleaned

def extract_urls_from_text(text: str) -> List[str]:
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„Ù†Øµ"""
    if not text:
        return []
    
    # Ù†Ù…Ø· Ù„Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    url_pattern = re.compile(
        r'https?://'  # http:// or https://
        r'(?:[A-Za-z0-9](?:[A-Za-z0-9-]{0,61}[A-Za-z0-9])?\.)+'  # domain
        r'[A-Za-z]{2,6}'  # TLD
        r'(?:[/\w .?=&%-]*)?',  # path and query
        re.IGNORECASE
    )
    
    urls = url_pattern.findall(text)
    return clean_url_list(urls)

# ======================
# Quality Checks
# ======================

def estimate_group_activity(url: str) -> str:
    """ØªÙ‚Ø¯ÙŠØ± Ù†Ø´Ø§Ø· Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø·"""
    analysis = analyze_link(url)
    
    if not analysis['is_valid'] or not analysis['should_collect']:
        return 'unknown'
    
    platform = analysis['platform']
    link_type = analysis['link_type']
    
    if platform == 'telegram':
        if link_type == 'public_group':
            username = analysis['details'].get('username', '')
            if username:
                # Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø°Ø§Øª Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¹Ø§Ø¯Ø© Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ø§Ù‹
                if len(username) <= 10:
                    return 'high'
                elif len(username) <= 20:
                    return 'medium'
                else:
                    return 'low'
        
        elif link_type == 'private_group':
            # Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø®Ø§ØµØ© Ø¹Ø§Ø¯Ø© Ø£ÙƒØ«Ø± Ù†Ø´Ø§Ø·Ø§Ù‹
            return 'high'
    
    elif platform == 'whatsapp':
        # Ù…Ø¬Ù…ÙˆØ¹Ø§Øª ÙˆØ§ØªØ³Ø§Ø¨ Ø¹Ø§Ø¯Ø© Ù†Ø´Ø·Ø©
        return 'medium'
    
    return 'low'

def is_premium_group(url: str) -> bool:
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù…Ø§ Ø¥Ø°Ø§ ÙƒØ§Ù†Øª Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù…ÙŠØ²Ø© (Ù…Ø­ØªÙ…Ù„Ø©)"""
    analysis = analyze_link(url)
    
    if not analysis['is_valid'] or not analysis['should_collect']:
        return False
    
    platform = analysis['platform']
    link_type = analysis['link_type']
    
    if platform == 'telegram' and link_type == 'public_group':
        username = analysis['details'].get('username', '')
        if username:
            # Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø°Ø§Øª Ø§Ù„Ø£Ø³Ù…Ø§Ø¡ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¹Ø§Ø¯Ø© Ù…Ù…ÙŠØ²Ø©
            if len(username) <= 8:
                return True
            
            # ÙƒÙ„Ù…Ø§Øª ØªØ´ÙŠØ± Ø¥Ù„Ù‰ Ø§Ù„Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ù…Ù…ÙŠØ²Ø©
            premium_keywords = ['vip', 'premium', 'gold', 'elite', 'exclusive', 'private']
            if any(keyword in username.lower() for keyword in premium_keywords):
                return True
    
    return False

# ======================
# Export Utilities
# ======================

def format_links_for_export(links: List[str], platform: str = None, link_type: str = None) -> str:
    """ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù„Ù„ØªØµØ¯ÙŠØ±"""
    if not links:
        return ""
    
    header = []
    if platform:
        header.append(f"Ø§Ù„Ù…Ù†ØµØ©: {platform}")
    if link_type:
        header.append(f"Ø§Ù„Ù†ÙˆØ¹: {link_type}")
    header.append(f"Ø§Ù„Ø¹Ø¯Ø¯: {len(links)}")
    header.append(f"Ø§Ù„ØªØ§Ø±ÙŠØ®: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    output = "# " + " | ".join(header) + "\n"
    output += "#" * 60 + "\n\n"
    
    for i, url in enumerate(links, 1):
        output += f"{url}\n"
    
    return output

def group_links_by_type(links: List[str]) -> Dict[str, List[str]]:
    """ØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹"""
    grouped = {
        'telegram_public_groups': [],
        'telegram_private_groups': [],
        'whatsapp_groups': [],
        'other': []
    }
    
    for url in links:
        analysis = analyze_link(url)
        
        if not analysis['is_valid'] or not analysis['should_collect']:
            continue
        
        platform = analysis['platform']
        link_type = analysis['link_type']
        
        if platform == 'telegram':
            if link_type == 'public_group':
                grouped['telegram_public_groups'].append(url)
            elif link_type == 'private_group':
                grouped['telegram_private_groups'].append(url)
        
        elif platform == 'whatsapp' and link_type == 'group':
            grouped['whatsapp_groups'].append(url)
        
        else:
            grouped['other'].append(url)
    
    return grouped

# ======================
# Test Functions
# ======================

def test_link_analysis():
    """Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·"""
    test_urls = [
        "https://t.me/test_group",
        "https://t.me/+ABC123def",
        "https://t.me/channel_news",
        "https://chat.whatsapp.com/ABC123def",
        "https://wa.me/966501234567",
        "https://t.me/c/1234567890",
        "https://t.me/test_bot",
        "https://facebook.com/groups/test",
        "https://t.me/group_vip",
        "https://t.me/arabic_chat_group"
    ]
    
    print("ğŸ” Ø§Ø®ØªØ¨Ø§Ø± ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·...")
    print("=" * 80)
    
    for url in test_urls:
        analysis = analyze_link(url)
        
        print(f"\nğŸ“Œ Ø§Ù„Ø±Ø§Ø¨Ø·: {url}")
        print(f"   ğŸ“± Ø§Ù„Ù…Ù†ØµØ©: {analysis['platform']}")
        print(f"   ğŸ·ï¸  Ø§Ù„Ù†ÙˆØ¹: {analysis['link_type']}")
        print(f"   âœ… ØµØ§Ù„Ø­: {analysis['is_valid']}")
        print(f"   ğŸ¤– ÙŠØ¬Ø¨ Ø§Ù„Ø¬Ù…Ø¹: {analysis['should_collect']}")
        print(f"   ğŸ“ Ø§Ù„Ø³Ø¨Ø¨: {analysis['reason']}")
        
        if analysis['details']:
            print(f"   ğŸ” Ø§Ù„ØªÙØ§ØµÙŠÙ„: {analysis['details']}")
    
    print("\n" + "=" * 80)
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø¯ÙØ¹Ø©
    print("\nğŸ“Š ØªØ­Ù„ÙŠÙ„ Ø¯ÙØ¹Ø© Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø·...")
    batch_results = analyze_links_batch(test_urls)
    
    print(f"   ğŸ“ˆ Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ: {batch_results['total']}")
    print(f"   âœ… Ø§Ù„ØµØ§Ù„Ø­Ø©: {batch_results['valid']}")
    print(f"   âŒ ØºÙŠØ± Ø§Ù„ØµØ§Ù„Ø­Ø©: {batch_results['invalid']}")
    print(f"   â­ï¸  Ø§Ù„Ù…ØªØ¬Ø§Ù‡Ù„Ø©: {batch_results['ignored']}")
    print(f"   ğŸ¯ Ù„Ù„Ø¬Ù…Ø¹: {batch_results['to_collect']}")
    
    print(f"\n   ğŸ“± Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ©:")
    for platform, count in batch_results['by_platform'].items():
        print(f"      â€¢ {platform}: {count}")
    
    print(f"\n   ğŸ·ï¸  Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹:")
    for link_type, count in batch_results['by_type'].items():
        print(f"      â€¢ {link_type}: {count}")

# ======================
# Main Entry Point
# ======================

if __name__ == "__main__":
    import sys
    
    print("ğŸ”§ ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± link_utils.py...")
    print("âš¡ Ù‡Ø°Ø§ Ø§Ù„Ù…Ù„Ù ÙŠÙˆÙØ± Ø£Ø¯ÙˆØ§Øª ØªØ­Ù„ÙŠÙ„ ÙˆØªØµÙ†ÙŠÙ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·")
    
    # Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
    test_url = "https://t.me/test_group"
    
    print(f"\nğŸ“Œ Ù…Ø«Ø§Ù„ Ø¹Ù„Ù‰ Ø§Ù„Ø±Ø§Ø¨Ø·: {test_url}")
    
    normalized = normalize_url(test_url)
    print(f"   ğŸ”„ ØªØ·Ø¨ÙŠØ¹: {normalized}")
    
    url_hash = get_url_hash(test_url)
    print(f"   ğŸ” Ø§Ù„Ù€ Hash: {url_hash}")
    
    platform = detect_platform(test_url)
    print(f"   ğŸ“± Ø§Ù„Ù…Ù†ØµØ©: {platform}")
    
    is_group, group_type = is_telegram_group_link(test_url)
    print(f"   ğŸ‘¥ Ù…Ø¬Ù…ÙˆØ¹Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…: {is_group} ({group_type})")
    
    is_channel = is_telegram_channel_link(test_url)
    print(f"   ğŸ“¢ Ù‚Ù†Ø§Ø© ØªÙŠÙ„ÙŠØ¬Ø±Ø§Ù…: {is_channel}")
    
    # ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„
    analysis = analyze_link(test_url)
    print(f"\nğŸ” Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø§Ù…Ù„:")
    for key, value in analysis.items():
        if isinstance(value, dict) and value:
            print(f"   ğŸ“Š {key}:")
            for k, v in value.items():
                print(f"      â€¢ {k}: {v}")
        elif value:
            print(f"   ğŸ“Š {key}: {value}")
    
    # ØªØ´ØºÙŠÙ„ Ø§Ø®ØªØ¨Ø§Ø± ÙƒØ§Ù…Ù„
    print("\n" + "=" * 80)
    test_link_analysis()
    
    print("\nâœ… Ø§Ø®ØªØ¨Ø§Ø± link_utils.py Ø§ÙƒØªÙ…Ù„ Ø¨Ù†Ø¬Ø§Ø­!")
