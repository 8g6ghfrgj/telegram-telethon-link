import re
import asyncio
import logging
from typing import List, Optional, Tuple, Dict, Set
from urllib.parse import urlparse

from telethon.tl.types import Message

from config import VERIFY_LINKS, VERIFY_TIMEOUT, BLACKLISTED_DOMAINS

# ======================
# Logging Configuration
# ======================

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

# ======================
# Regex Patterns
# ======================

URL_REGEX = re.compile(
    r"(https?://[^\s<>\"]+)",
    re.IGNORECASE
)

# Ø£Ù†Ù…Ø§Ø· Ø§Ù„Ù…Ù†ØµØ§Øª
PLATFORM_PATTERNS = {
    "telegram": re.compile(r"(t\.me|telegram\.me)", re.IGNORECASE),
    "whatsapp": re.compile(r"(wa\.me|chat\.whatsapp\.com)", re.IGNORECASE),
}

# Ø£Ù†Ù…Ø§Ø· Ù…Ø­Ø¯Ø¯Ø© Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…
TELEGRAM_PATTERNS = {
    "channel": re.compile(r"https?://t\.me/([A-Za-z0-9_]+)$", re.I),
    "private_group": re.compile(r"https?://t\.me/joinchat/([A-Za-z0-9_-]+)", re.I),
    "public_group": re.compile(r"https?://t\.me/\+([A-Za-z0-9]+)", re.I),
    "bot": re.compile(r"https?://t\.me/([A-Za-z0-9_]+)bot(\?|$)", re.I),
    "message": re.compile(r"https?://t\.me/(c/)?([A-Za-z0-9_]+)/(\d+)", re.I),
}

# Ø£Ù†Ù…Ø§Ø· Ù…Ø­Ø¯Ø¯Ø© Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ÙˆØ§ØªØ³Ø§Ø¨
WHATSAPP_PATTERNS = {
    "group": re.compile(r"https?://chat\.whatsapp\.com/([A-Za-z0-9]+)", re.I),
    "phone": re.compile(r"https?://wa\.me/(\d+)", re.I),
}

# ======================
# Link Cleaning Functions
# ======================

def clean_link(url: str) -> str:
    """
    ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ù† Ø§Ù„Ø²ÙˆØ§Ø¦Ø¯ (Ù†Ø¬ÙˆÙ…ØŒ Ù…Ø³Ø§ÙØ§ØªØŒ Ø¥Ù„Ø®)
    
    Args:
        url: Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø®Ø§Ù…
        
    Returns:
        str: Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ù†Ø¸ÙŠÙ
    """
    if not url or not isinstance(url, str):
        return ""
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…Ø³Ø§ÙØ§Øª ÙˆØ§Ù„Ù†Ø¬ÙˆÙ…
    cleaned = url.strip().replace('*', '').replace(' ', '')
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø£Ø­Ø±Ù Ø§Ù„ØºØ±ÙŠØ¨Ø© ÙÙŠ Ø§Ù„Ø¨Ø¯Ø§ÙŠØ© ÙˆØ§Ù„Ù†Ù‡Ø§ÙŠØ©
    cleaned = re.sub(r'^[^a-zA-Z0-9]+', '', cleaned)
    cleaned = re.sub(r'[^a-zA-Z0-9]+$', '', cleaned)
    
    # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ù…ØªÙƒØ±Ø±Ø§Øª Ù…Ù† ///
    cleaned = re.sub(r'/{2,}', '/', cleaned)
    
    # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø£Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠØ¨Ø¯Ø£ Ø¨Ù€ http:// Ø£Ùˆ https://
    if cleaned and not cleaned.startswith(('http://', 'https://')):
        cleaned = 'https://' + cleaned
    
    return cleaned

def is_valid_url(url: str) -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø§Ø¨Ø·
    
    Args:
        url: Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„ØªØ­Ù‚Ù‚
        
    Returns:
        bool: True Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ØµØ§Ù„Ø­Ø§Ù‹
    """
    if not url:
        return False
    
    try:
        result = urlparse(url)
        return all([result.scheme in ['http', 'https'], result.netloc])
    except:
        return False

# ======================
# Link Extraction Functions
# ======================

def extract_links_from_text(text: str) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„Ù†Øµ
    
    Args:
        text: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù†Ù‡ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
    """
    if not text:
        return []
    
    links = set()
    for url in URL_REGEX.findall(text):
        cleaned = clean_link(url)
        if cleaned and is_valid_url(cleaned):
            links.add(cleaned)
    
    return list(links)

def extract_links_from_message(message: Message) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø±Ø³Ø§Ù„Ø© ØªÙ„ÙŠØ¬Ø±Ø§Ù…
    
    Args:
        message: ÙƒØ§Ø¦Ù† Ø§Ù„Ø±Ø³Ø§Ù„Ø© Ù…Ù† Telethon
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø©
    """
    links = set()
    
    # Ø§Ù„Ù†Øµ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø±Ø³Ø§Ù„Ø©
    text = message.text or message.message or ""
    if text:
        links.update(extract_links_from_text(text))
    
    # Ø§Ù„ÙƒØ§Ø¨ØªØ´Ù† (Ø¥Ø°Ø§ ÙƒØ§Ù†Øª ØµÙˆØ±Ø©/ÙÙŠØ¯ÙŠÙˆ)
    if hasattr(message, 'caption') and message.caption:
        links.update(extract_links_from_text(message.caption))
    
    # Ø£Ø²Ø±Ø§Ø± Inline
    if hasattr(message, 'reply_markup') and message.reply_markup:
        for row in message.reply_markup.rows:
            for button in row.buttons:
                if hasattr(button, "url") and button.url:
                    cleaned = clean_link(button.url)
                    if cleaned and is_valid_url(cleaned):
                        links.add(cleaned)
    
    # Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø®ÙÙŠØ© (Ø§Ù„ÙƒÙŠØ§Ù†Ø§Øª)
    if hasattr(message, 'entities') and message.entities:
        for entity in message.entities:
            if hasattr(entity, 'url') and entity.url:
                cleaned = clean_link(entity.url)
                if cleaned and is_valid_url(cleaned):
                    links.add(cleaned)
    
    return list(links)

# ======================
# Link Filtering Functions
# ======================

def is_blacklisted(url: str) -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙÙŠ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø³ÙˆØ¯Ø§Ø¡
    
    Args:
        url: Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„ØªØ­Ù‚Ù‚
        
    Returns:
        bool: True Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ù…Ù†ÙˆØ¹Ø§Ù‹
    """
    if not url or not BLACKLISTED_DOMAINS:
        return False
    
    url_lower = url.lower()
    for blacklisted in BLACKLISTED_DOMAINS:
        if blacklisted and blacklisted.lower() in url_lower:
            return True
    
    return False

def is_allowed_link(url: str) -> bool:
    """
    Ø§Ù„ØªØ­Ù‚Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø³Ù…ÙˆØ­Ø§Ù‹ Ø¨Ù‡ (ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ø£Ùˆ ÙˆØ§ØªØ³Ø§Ø¨ ÙÙ‚Ø·)
    
    Args:
        url: Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„ØªØ­Ù‚Ù‚
        
    Returns:
        bool: True Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø±Ø§Ø¨Ø· Ù…Ø³Ù…ÙˆØ­Ø§Ù‹ Ø¨Ù‡
    """
    # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ÙØ§Ø±ØºØ© Ø£Ùˆ Ø§Ù„Ù‚ØµÙŠØ±Ø©
    if not url or len(url) < 10:
        return False
    
    # ØªØ¬Ø§Ù‡Ù„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ù…Ù†ÙˆØ¹Ø©
    if is_blacklisted(url):
        return False
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±Ø§Ø¨Ø·
    if not is_valid_url(url):
        return False
    
    # Ø§Ù„Ø³Ù…Ø§Ø­ ÙÙ‚Ø· Ø¨Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù… ÙˆØ§Ù„ÙˆØ§ØªØ³Ø§Ø¨
    platform = classify_platform(url)
    return platform in ["telegram", "whatsapp"]

def filter_links(links: List[str]) -> List[str]:
    """
    ÙÙ„ØªØ±Ø© Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§ ÙÙ‚Ø·
    
    Args:
        links: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø®Ø§Ù…
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø³Ù…ÙˆØ­ Ø¨Ù‡Ø§
    """
    if not links:
        return []
    
    filtered_links = []
    for link in links:
        cleaned = clean_link(link)
        if cleaned and is_allowed_link(cleaned):
            filtered_links.append(cleaned)
    
    return filtered_links

# ======================
# Platform Classification
# ======================

def classify_platform(url: str) -> str:
    """
    ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù†ØµØ© (ØªÙ„ÙŠØ¬Ø±Ø§Ù… / ÙˆØ§ØªØ³Ø§Ø¨ / Ø£Ø®Ø±Ù‰)
    
    Args:
        url: Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„ØªØµÙ†ÙŠÙ
        
    Returns:
        str: Ø§Ø³Ù… Ø§Ù„Ù…Ù†ØµØ©
    """
    if not url:
        return "unknown"
    
    url_lower = url.lower()
    
    for platform, pattern in PLATFORM_PATTERNS.items():
        if pattern.search(url_lower):
            return platform
    
    return "other"

def classify_telegram_link(url: str) -> str:
    """
    ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø· Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…
    
    Args:
        url: Ø±Ø§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù…
        
    Returns:
        str: Ù†ÙˆØ¹ Ø§Ù„Ø±Ø§Ø¨Ø·
    """
    if not url:
        return "unknown"
    
    url_lower = url.lower()
    
    for link_type, pattern in TELEGRAM_PATTERNS.items():
        if pattern.search(url_lower):
            return link_type
    
    # Ø¥Ø°Ø§ Ù„Ù… ÙŠØªØ·Ø§Ø¨Ù‚ Ù…Ø¹ Ø§Ù„Ø£Ù†ÙˆØ§Ø¹ Ø§Ù„Ù…Ø¹Ø±ÙˆÙØ©ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ù…Ù†Ø·Ù‚ Ø¨Ø¯ÙŠÙ„
    parsed = urlparse(url_lower)
    path = parsed.path.strip('/')
    
    if path.startswith('joinchat/'):
        return "private_group"
    elif path.startswith('+'):
        return "public_group"
    elif 'bot' in path:
        return "bot"
    elif re.search(r'/\d+$', path):
        return "message"
    elif re.match(r'^[A-Za-z0-9_]+$', path):
        return "channel"
    
    return "unknown"

def classify_whatsapp_link(url: str) -> str:
    """
    ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø±Ø§Ø¨Ø· Ø§Ù„ÙˆØ§ØªØ³Ø§Ø¨
    
    Args:
        url: Ø±Ø§Ø¨Ø· ÙˆØ§ØªØ³Ø§Ø¨
        
    Returns:
        str: Ù†ÙˆØ¹ Ø§Ù„Ø±Ø§Ø¨Ø·
    """
    if not url:
        return "unknown"
    
    url_lower = url.lower()
    
    for link_type, pattern in WHATSAPP_PATTERNS.items():
        if pattern.search(url_lower):
            return link_type
    
    if "chat.whatsapp.com" in url_lower:
        return "group"
    elif "wa.me" in url_lower:
        return "phone"
    
    return "unknown"

# ======================
# Link Verification Functions
# ======================

async def verify_telegram_link(url: str) -> Tuple[bool, str, Dict]:
    """
    ÙØ­Øµ Ø±Ø§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù… (ÙˆØ¸ÙŠÙØ© Ù…Ø¨Ø³Ø·Ø©)
    
    Args:
        url: Ø±Ø§Ø¨Ø· ØªÙ„ÙŠØ¬Ø±Ø§Ù… Ù„Ù„ÙØ­Øµ
        
    Returns:
        tuple: (is_valid, link_type, metadata)
    """
    try:
        # ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…Ø¨Ø³Ø·ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ØªØµÙ†ÙŠÙ ÙÙ‚Ø·
        # ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„ ÙŠÙ…ÙƒÙ† Ø¥Ø¶Ø§ÙØ© ÙØ­Øµ HTTP Ù‡Ù†Ø§
        
        link_type = classify_telegram_link(url)
        
        metadata = {
            "platform": "telegram",
            "url": url,
            "verified_at": str(asyncio.get_event_loop().time())
        }
        
        # Ù†Ø¹ØªØ¨Ø± Ø¬Ù…ÙŠØ¹ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù… ØµØ§Ù„Ø­Ø© ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…Ø¨Ø³Ø·
        return True, link_type, metadata
        
    except Exception as e:
        logger.error(f"Error verifying telegram link {url}: {e}")
        return False, "error", {"error": str(e)}

async def verify_whatsapp_link(url: str) -> Tuple[bool, str, Dict]:
    """
    ÙØ­Øµ Ø±Ø§Ø¨Ø· ÙˆØ§ØªØ³Ø§Ø¨ (ÙˆØ¸ÙŠÙØ© Ù…Ø¨Ø³Ø·Ø©)
    
    Args:
        url: Ø±Ø§Ø¨Ø· ÙˆØ§ØªØ³Ø§Ø¨ Ù„Ù„ÙØ­Øµ
        
    Returns:
        tuple: (is_valid, link_type, metadata)
    """
    try:
        link_type = classify_whatsapp_link(url)
        
        metadata = {
            "platform": "whatsapp",
            "url": url,
            "verified_at": str(asyncio.get_event_loop().time())
        }
        
        # Ù†Ø¹ØªØ¨Ø± Ø¬Ù…ÙŠØ¹ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ÙˆØ§ØªØ³Ø§Ø¨ ØµØ§Ù„Ø­Ø© ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…Ø¨Ø³Ø·
        return True, link_type, metadata
        
    except Exception as e:
        logger.error(f"Error verifying whatsapp link {url}: {e}")
        return False, "error", {"error": str(e)}

async def verify_link(url: str) -> Tuple[bool, str, str, Dict]:
    """
    ÙØ­Øµ Ø§Ù„Ø±Ø§Ø¨Ø· Ø§Ù„Ø¹Ø§Ù… (ÙŠØ®ØªØ§Ø± Ø§Ù„ÙˆØ¸ÙŠÙØ© Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ©)
    
    Args:
        url: Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„ÙØ­Øµ
        
    Returns:
        tuple: (is_valid, platform, link_type, metadata)
    """
    if not VERIFY_LINKS:
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙØ­Øµ Ù…Ø¹Ø·Ù„Ø§Ù‹ØŒ Ù†Ø±Ø¬Ø¹ Ù‚ÙŠÙ…Ø§Ù‹ Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        platform = classify_platform(url)
        if platform == "telegram":
            link_type = classify_telegram_link(url)
        elif platform == "whatsapp":
            link_type = classify_whatsapp_link(url)
        else:
            link_type = "other"
        
        return True, platform, link_type, {}
    
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„ÙØ­Øµ Ù…ÙØ¹Ù„Ø§Ù‹ØŒ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
    platform = classify_platform(url)
    
    if platform == "telegram":
        is_valid, link_type, metadata = await verify_telegram_link(url)
        if is_valid:
            return True, platform, link_type, metadata
        else:
            return False, platform, link_type, metadata
            
    elif platform == "whatsapp":
        is_valid, link_type, metadata = await verify_whatsapp_link(url)
        if is_valid:
            return True, platform, link_type, metadata
        else:
            return False, platform, link_type, metadata
            
    else:
        return False, "other", "not_supported", {}

async def verify_links_batch(urls: List[str]) -> List[Dict]:
    """
    ÙØ­Øµ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¨Ø´ÙƒÙ„ Ù…ØªØ²Ø§Ù…Ù†
    
    Args:
        urls: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù„Ù„ÙØ­Øµ
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ­Øµ
    """
    if not urls:
        return []
    
    results = []
    
    # ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„Ù…Ø¨Ø³Ø·ØŒ Ù†ÙØ­Øµ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¨Ø´ÙƒÙ„ Ù…ØªØ³Ù„Ø³Ù„
    # ÙÙŠ Ø§Ù„Ø¥ØµØ¯Ø§Ø± Ø§Ù„ÙƒØ§Ù…Ù„ ÙŠÙ…ÙƒÙ† Ø§Ø³ØªØ®Ø¯Ø§Ù… asyncio.gather Ù„Ù„ÙØ­Øµ Ø§Ù„Ù…ØªÙˆØ§Ø²ÙŠ
    for url in urls:
        try:
            is_valid, platform, link_type, metadata = await verify_link(url)
            
            results.append({
                'url': url,
                'is_valid': is_valid,
                'platform': platform,
                'link_type': link_type,
                'metadata': metadata
            })
            
        except Exception as e:
            logger.error(f"Error verifying link {url}: {e}")
            results.append({
                'url': url,
                'is_valid': False,
                'platform': 'error',
                'link_type': 'error',
                'metadata': {'error': str(e)}
            })
    
    return results

async def verify_links_batch_concurrent(urls: List[str], max_concurrent: int = 5) -> List[Dict]:
    """
    ÙØ­Øµ Ù…Ø¬Ù…ÙˆØ¹Ø© Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¨Ø´ÙƒÙ„ Ù…ØªØ²Ø§Ù…Ù† Ù…Ø¹ Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„Ø¹Ø¯Ø¯
    
    Args:
        urls: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù„Ù„ÙØ­Øµ
        max_concurrent: Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ØªØ²Ø§Ù…Ù†Ø©
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ÙØ­Øµ
    """
    if not urls:
        return []
    
    semaphore = asyncio.Semaphore(max_concurrent)
    
    async def verify_with_semaphore(url):
        async with semaphore:
            return await verify_link(url)
    
    tasks = []
    for url in urls:
        task = asyncio.create_task(verify_with_semaphore(url))
        tasks.append((url, task))
    
    results = []
    for url, task in tasks:
        try:
            is_valid, platform, link_type, metadata = await task
            
            results.append({
                'url': url,
                'is_valid': is_valid,
                'platform': platform,
                'link_type': link_type,
                'metadata': metadata
            })
            
        except Exception as e:
            logger.error(f"Error verifying link {url}: {e}")
            results.append({
                'url': url,
                'is_valid': False,
                'platform': 'error',
                'link_type': 'error',
                'metadata': {'error': str(e)}
            })
    
    return results

# ======================
# Link Analysis Functions
# ======================

def analyze_links(links: List[str]) -> Dict:
    """
    ØªØ­Ù„ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
    
    Args:
        links: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        
    Returns:
        dict: Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„ØªØ­Ù„ÙŠÙ„
    """
    stats = {
        "total": len(links),
        "telegram": 0,
        "whatsapp": 0,
        "other": 0,
        "valid": 0,
        "invalid": 0,
        "by_type": {}
    }
    
    for link in links:
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØµØ­Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        if is_valid_url(link):
            stats["valid"] += 1
        else:
            stats["invalid"] += 1
        
        # Ø§Ù„ØªØµÙ†ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ©
        platform = classify_platform(link)
        if platform in stats:
            stats[platform] += 1
        else:
            stats["other"] += 1
        
        # Ø§Ù„ØªØµÙ†ÙŠÙ Ø­Ø³Ø¨ Ø§Ù„Ù†ÙˆØ¹
        if platform == "telegram":
            link_type = classify_telegram_link(link)
        elif platform == "whatsapp":
            link_type = classify_whatsapp_link(link)
        else:
            link_type = "other"
        
        if link_type in stats["by_type"]:
            stats["by_type"][link_type] += 1
        else:
            stats["by_type"][link_type] = 1
    
    return stats

def get_unique_domains(links: List[str]) -> List[str]:
    """
    Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø© Ù…Ù† Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    
    Args:
        links: Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
        
    Returns:
        list: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ù†Ø·Ø§Ù‚Ø§Øª Ø§Ù„ÙØ±ÙŠØ¯Ø©
    """
    domains = set()
    
    for link in links:
        try:
            parsed = urlparse(link)
            if parsed.netloc:
                domains.add(parsed.netloc)
        except:
            continue
    
    return sorted(list(domains))

# ======================
# Export Functions
# ======================

def format_links_for_export(links: List[Dict], include_metadata: bool = False) -> str:
    """
    ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù„Ù„ØªØµØ¯ÙŠØ±
    
    Args:
        links: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§ØªÙ‡Ø§
        include_metadata: ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©
        
    Returns:
        str: Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ù†Ø³Ù‚
    """
    if not links:
        return ""
    
    output = []
    
    for link in links:
        url = link.get('url', '')
        platform = link.get('platform', 'unknown')
        link_type = link.get('link_type', 'unknown')
        
        if include_metadata and link.get('metadata'):
            metadata_str = str(link.get('metadata'))
            output.append(f"{url} | {platform} | {link_type} | {metadata_str}")
        else:
            output.append(f"{url} | {platform} | {link_type}")
    
    return "\n".join(output)

def export_links_by_platform(links: List[Dict]) -> Dict[str, str]:
    """
    ØªØµØ¯ÙŠØ± Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…ØµÙ†ÙØ© Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ©
    
    Args:
        links: Ù‚Ø§Ø¦Ù…Ø© Ø¨Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù…Ø¹ Ø¨ÙŠØ§Ù†Ø§ØªÙ‡Ø§
        
    Returns:
        dict: Ù†ØµÙˆØµ Ù…ØµÙ†ÙØ© Ø­Ø³Ø¨ Ø§Ù„Ù…Ù†ØµØ©
    """
    platforms = {}
    
    for link in links:
        platform = link.get('platform', 'other')
        url = link.get('url', '')
        
        if platform not in platforms:
            platforms[platform] = []
        
        platforms[platform].append(url)
    
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ù†ØµÙˆØµ
    result = {}
    for platform, urls in platforms.items():
        result[platform] = "\n".join(urls)
    
    return result

# ======================
# Test Functions
# ======================

async def test_link_utils():
    """
    Ø§Ø®ØªØ¨Ø§Ø± Ø¬Ù…ÙŠØ¹ ÙˆØ¸Ø§Ø¦Ù link_utils
    """
    print("\n" + "="*50)
    print("ğŸ§ª Testing Link Utilities Module")
    print("="*50)
    
    # Ø±ÙˆØ§Ø¨Ø· Ø§Ø®ØªØ¨Ø§Ø±ÙŠØ©
    test_links = [
        " * https://t.me/python_ar * ",
        "  https://t.me/joinchat/abcdefg  ",
        "https://t.me/+1234567890",
        "https://t.me/test_bot",
        "https://t.me/c/1234567890/123",
        "https://chat.whatsapp.com/abc123def",
        "https://wa.me/1234567890",
        "https://example.com",
        "invalid url",
        "  *  https://t.me/telegram  *  "
    ]
    
    # 1. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙ†Ø¸ÙŠÙ
    print("\n1. Testing link cleaning:")
    for link in test_links[:3]:
        cleaned = clean_link(link)
        print(f"   '{link}' -> '{cleaned}'")
    
    # 2. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØµÙ†ÙŠÙ
    print("\n2. Testing platform classification:")
    test_classification = [
        "https://t.me/test",
        "https://chat.whatsapp.com/abc",
        "https://example.com"
    ]
    
    for link in test_classification:
        platform = classify_platform(link)
        print(f"   {link} -> {platform}")
    
    # 3. Ø§Ø®ØªØ¨Ø§Ø± ØªØµÙ†ÙŠÙ Ø§Ù„ØªÙ„ÙŠØ¬Ø±Ø§Ù…
    print("\n3. Testing telegram link classification:")
    telegram_links = [
        "https://t.me/channel",
        "https://t.me/joinchat/abc",
        "https://t.me/+invite",
        "https://t.me/test_bot",
        "https://t.me/c/123/456"
    ]
    
    for link in telegram_links:
        link_type = classify_telegram_link(link)
        print(f"   {link} -> {link_type}")
    
    # 4. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ÙÙ„ØªØ±Ø©
    print("\n4. Testing link filtering:")
    filtered = filter_links(test_links)
    print(f"   Total links: {len(test_links)}")
    print(f"   Filtered links: {len(filtered)}")
    
    # 5. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù‚Ù‚
    print("\n5. Testing link verification:")
    verification_links = test_links[:5]
    
    for link in verification_links:
        is_valid, platform, link_type, metadata = await verify_link(link)
        status = "âœ…" if is_valid else "âŒ"
        print(f"   {status} {link} -> {platform}/{link_type}")
    
    # 6. Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªØ­Ù„ÙŠÙ„
    print("\n6. Testing link analysis:")
    stats = analyze_links(filtered)
    print(f"   Total: {stats['total']}")
    print(f"   Telegram: {stats['telegram']}")
    print(f"   WhatsApp: {stats['whatsapp']}")
    print(f"   Valid: {stats['valid']}")
    
    print("\n" + "="*50)
    print("âœ… Link Utilities test completed successfully!")
    print("="*50)

# ======================
# Main Test
# ======================

if __name__ == "__main__":
    import asyncio
    
    # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±
    asyncio.run(test_link_utils())
